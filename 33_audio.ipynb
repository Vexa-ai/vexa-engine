{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "from llmware.models import ModelCatalog\n",
    "from llmware.gguf_configs import GGUFConfigs\n",
    "\n",
    "GGUFConfigs().set_config(\"whisper_cpp_verbose\", \"TRUE\")\n",
    "GGUFConfigs().set_config(\"whisper_cpp_realtime_display\", True)\n",
    "GGUFConfigs().set_config(\"whisper_language\", \"ru\")\n",
    "GGUFConfigs().set_config(\"whisper_remove_segment_markers\", False)  # Make sure we see segments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "whisper_init_from_file_with_params_no_state: loading model from '/home/dima/llmware_data/model_repo/whisper-cpp-base/ggml-base.bin'\n",
      "whisper_model_load: loading model\n",
      "whisper_model_load: n_vocab       = 51865\n",
      "whisper_model_load: n_audio_ctx   = 1500\n",
      "whisper_model_load: n_audio_state = 512\n",
      "whisper_model_load: n_audio_head  = 8\n",
      "whisper_model_load: n_audio_layer = 6\n",
      "whisper_model_load: n_text_ctx    = 448\n",
      "whisper_model_load: n_text_state  = 512\n",
      "whisper_model_load: n_text_head   = 8\n",
      "whisper_model_load: n_text_layer  = 6\n",
      "whisper_model_load: n_mels        = 80\n",
      "whisper_model_load: ftype         = 1\n",
      "whisper_model_load: qntvr         = 0\n",
      "whisper_model_load: type          = 2 (base)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "whisper_model_load: adding 1608 extra tokens\n",
      "whisper_model_load: n_langs       = 99\n",
      "whisper_model_load:      CPU total size =   147.37 MB\n",
      "whisper_model_load: model size    =  147.37 MB\n",
      "whisper_init_state: kv self size  =   16.52 MB\n",
      "whisper_init_state: kv cross size =   18.43 MB\n",
      "whisper_init_state: compute buffer (conv)   =   16.39 MB\n",
      "whisper_init_state: compute buffer (encode) =  132.07 MB\n",
      "whisper_init_state: compute buffer (cross)  =    4.78 MB\n",
      "whisper_init_state: compute buffer (decode) =   96.48 MB\n"
     ]
    }
   ],
   "source": [
    "#   choose between english-only and multilingual\n",
    "whisper_base_english = \"whisper-cpp-base-english\"\n",
    "whisper_base_multi = \"whisper-cpp-base\"\n",
    "\n",
    "#   load and run inference like any other model in llmware\n",
    "model = ModelCatalog().load_model(whisper_base_multi, use_gpu=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.BufferedRandom name='/home/dima/playground/dev_multiassistant/f5560572-aa95-4752-b251-39db4dba8fde.wav'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ... existing imports ...\n",
    "\n",
    "# Define paths consistently\n",
    "fp_source = \"/home/andrew/volumes/audio\"\n",
    "fn_source = \"f5560572-aa95-4752-b251-39db4dba8fde.webm\"\n",
    "fp_dest = \"/home/dima/playground/dev_multiassistant\"\n",
    "\n",
    "# Convert webm to wav\n",
    "webm_file = os.path.join(fp_source, fn_source)\n",
    "wav_file = os.path.join(fp_dest, fn_source.replace('.webm', '.wav'))\n",
    "\n",
    "audio = AudioSegment.from_file(webm_file, format=\"webm\")\n",
    "audio.export(wav_file, format=\"wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.BufferedRandom name='/home/dima/playground/dev_multiassistant/f5560572-aa95-4752-b251-39db4dba8fde.wav'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio = AudioSegment.from_file(webm_file, format=\"webm\")\n",
    "audio = audio.set_frame_rate(16000)\n",
    "audio = audio.set_channels(1)\n",
    "audio = audio.set_sample_width(2)  # 16-bit\n",
    "audio.export(wav_file, format=\"wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:00:00.000 --> 00:00:13.400]  [_BEG_] Так сейчас вопрос просто будет слушать, что вы знаете, что вы говорили? Да, там очень хороший список рецепт-контакток.[_TT_670]\n",
      "[00:00:13.400 --> 00:00:20.400]  [_BEG_] К контакток. Усажно целевые для нас.[_TT_350]\n",
      "[00:00:20.400 --> 00:00:35.400]   Вот, если вы говорите система, которую у тебя записывает режим рельно-римнее, то, чему творите, это просто, кстати, пример привел.[_TT_1100]\n",
      "[00:00:35.400 --> 00:00:40.400]   Она работает по консмаху с вуглмит, то есть можно расширение либо холм, либо для инфраузы.[_TT_1350]\n",
      "[00:00:40.400 --> 00:00:46.400]  [_BEG_] В этом, то, может, захватить воссис, он написает ему разные запросы, которые эксперимужные. Он их возит, по примеру, не отчет.[_TT_300]\n",
      "[00:00:46.400 --> 00:00:53.400]   Скажи, кто что сказал, начинал договорились, а вспомнишь, что он начинал, а пересвозирует так, то, что это все будет делать.[_TT_650]\n",
      "[00:00:53.400 --> 00:00:56.400]   Что задвижал, что я предупрежил?[_TT_800]\n",
      "[00:00:56.400 --> 00:00:58.400]   То, что с тобой джипет?[_TT_900]\n",
      "[00:00:58.400 --> 00:01:01.400]   То есть, на углубая мы сделали, мы сделали то, что за это?[_TT_1050]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored on calling ctypes callback function: <bound method WhisperCPPModel.callback of <llmware.models.WhisperCPPModel object at 0x7f50ff790250>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dima/anaconda3/envs/langchain/lib/python3.11/site-packages/llmware/models.py\", line 10330, in callback\n",
      "    def callback(self, ctx, state, i, p):\n",
      "\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "llm response:  [_BEG_] Так сейчас вопрос просто будет слушать, что вы знаете, что вы говорили? Да, там очень хороший список рецепт-контакток.[_TT_670][_BEG_] К контакток. Усажно целевые для нас.[_TT_350] Вот, если вы говорите система, которую у тебя записывает режим рельно-римнее, то, чему творите, это просто, кстати, пример привел.[_TT_1100] Она работает по консмаху с вуглмит, то есть можно расширение либо холм, либо для инфраузы.[_TT_1350][_BEG_] В этом, то, может, захватить воссис, он написает ему разные запросы, которые эксперимужные. Он их возит, по примеру, не отчет.[_TT_300] Скажи, кто что сказал, начинал договорились, а вспомнишь, что он начинал, а пересвозирует так, то, что это все будет делать.[_TT_650] Что задвижал, что я предупрежил?[_TT_800] То, что с тобой джипет?[_TT_900] То есть, на углубая мы сделали, мы сделали то, что за это?[_TT_1050][_BEG_] Мы сделали запись, мы сделали запись сегодня, мы не тревируем его через рельно-римнее в текст, и потом глобально когда ты пишешь запрос, ты обращаешься к тому, кто и наборит текст, который уже его с первого расширает, что-то джипитель.[_TT_650] То есть он, в общем, в дай, но...[_TT_750] Время не записывает, кто лерсирует в текст.[_TT_850] В правом, хранит в себе это на баклоге, а потом более это, по-частому, еще, после выкашу.[_TT_1050][_BEG_] Время не ответится, вот, потом у тебя есть личный кабинет, а где у тебя хранятся твои диалоги, которые у тебя были?[_TT_700] То есть, где ты идти?[_TT_800] То есть он тебе на почту должен припся.[_TT_900][_BEG_] Если ты дождь, мне не так идти, мне так идти, мне не пиши, мне так идти.[_TT_1450][_BEG_] Сейчас.[_TT_50] Сейчас.[_TT_450] - Я постель хочу. - Короче.[_TT_500] - Это я, это сейчас, я скажу.[_TT_600] - Ну, в общем, вот, фольчиком. - Кочки.[_TT_700] - Ча? - А ты как запасовывался?[_TT_800] - Курки. - Курки, блять, я не курочка.[_TT_950] - Ну, в начале, у тебя есть хранится твои старые диалоги?[_TT_1100] - Все записпани, мы там немножко не вернутся, и сделаем запрос, смотрю, или нет.[_TT_1300] Ты все он помнят все, а чего ты же разговаривался?[_TT_1400][_BEG_] - Отдей ты хранится?[_TT_100] - Ну, это наш облакает, вы не ваше.[_TT_200] Это на наш стороне уже делается.[_TT_350] - Зум. - Мы сейчас делаем интократию зум, Майка Совтимс.[_TT_750] - А где он сейчас? - Зюл.[_TT_850] - Да, Толь. - А, я там же где-то выскупал.[_TT_1050] - Давай.[_TT_1200][_BEG_] - Сейчас.[_TT_100] - Четыре, четыре, четыре, четыре, четыре, четыре, четыре.[_TT_700] - У вас трасса, с нователем, Толя.[_TT_1150][_BEG_] - Это Венченнадий фонд.[_TT_100] - А, да. - Ну относительно, размерынки.[_TT_300] - Мне так государная сторона.[_TT_600] - Ну, у нас там вот здесь, вы получили один из этих переверстейских фондов.[_TT_900] - Это, ну, слушай, но это не просто тогда ее тоже.[_TT_1050] - Нет, в 90-е они, вот так и динить ее еще.[_TT_1200] - Да.[_TT_1300] - Динить.[_TT_1400][_BEG_] - В конце концов, это новая видеть.[_TT_100] - Нет, ну, рулокая, ничего там нет.[_TT_200] - Рвокана в манете у нас слушает.[_TT_400] - Угу. - Рвокана в манете у нас слушает.[_TT_500] - Еще такое на тема, расстанно называть.[_TT_600] - Нет, по себе, сколько один.[_TT_750] - Тоже появились, наверное.[_TT_950] - Их там чуть не посадили.[_TT_1050] - Ого. - Рвка.[_TT_1150] - Которые выбирают?[_TT_1250] - Нет, рвока, который и наши.[_TT_1400][_BEG_] - А, рвокат, он где-то в день, где не поместил.[_TT_100] - Хочу вам, ну, сейчас он стопал.[_TT_200] - Нормально. - Андрейфа.[_TT_300] - Андрейфа, Морозг не стопал по нам, где он стопал.[_TT_450] - Где он? - Да, да.[_TT_550] - Наши Морозг не здесь? - Да.[_TT_600] - Нет, он сейчас не здесь.[_TT_750] - Другой другом есть.[_TT_850] - Нет.[_TT_900] - Но, смотри, знаете, на неделе, на прошлом неделе.[_TT_1050] - А он чешен своего так.[_TT_1250] - Не салбезок.[_TT_1350] - А кто?[_TT_1450][_BEG_] - Он был в руссап.[_TT_150] - Вот плавально все это искусили, мы получается, занимались.[_TT_950] - До садельное разработки лишений.[_TT_1100] - То есть, новый ввод слову, в лище, в закон с генерил.[_TT_1200] - Заванную только он почему-то здесь начал делать с день, в восторых, как я знаю.[_TT_1400][_TT_50] - Вот.[_TT_150] - Ты, это, что у нас не было?[_TT_250] - Ты выгодали 300.[_TT_350] - Да, я вижу, сейчас их воскресенье.[_TT_450] - Чё, конечно, что?[_TT_550] - Да, это от чего?[_TT_650] - Ну, вот, вот.[_TT_700] - Тем же, там, только, сейчас мы на эжетовом отеле, специализируемся, да, это у нас были на деле в тюберпе, зима, геодома, в тюберпе.[_TT_1050] - Да, в тюберпе, в тюберпе, в тюберпе, вы ридомастные тюберпи.[_TT_1200] - Что, стопал?[_TT_1250] - В ридонасной этой арбе сады таки.[_TT_1350] - А тебе был дело, да.[_TT_1450][_BEG_] - В тюберпе, я думаю, нет.[_TT_100] - Нет, нет.[_TT_200] - Нет.[_TT_250] - В тюберпе, я думаю, нет.[_TT_350] - Нет, нет.[_TT_400] - В тюберпе.[_TT_450] - Но я здесь, когда-то заслывил.[_TT_550] - Я здесь, в тюберпе, я решил заслывил.[_TT_650] - На канале сведя старел его зелеское арморское, то аркетрации дральфика.[_TT_900] - На и поверхности, по икотозелески, я постоял ее в речении, которые ковмизывалось в речении.[_TT_1100] - А как?[_TT_1150] - Арбах.[_TT_1200] - Арбер, да.[_TT_1250] - Ну, с железка армизовалась.[_TT_1300][_BEG_] - А решение, когда беда работал, компания телефон бежен будет.[_TT_200] - Сераспать.[_TT_300] - Вот и есть пространство.[_TT_500] - Ну, антидос, он был от разного, он был антидосновым.[_TT_700] - А, он был антидосновым.[_TT_800] - А, что говоришь, антибот?[_TT_900] - Да, надо.[_TT_950] - У меня было желанные модели, у меня с эвапой сразу.[_TT_1100] - А тебе ботновым?[_TT_1150] - Нет, у меня на эвапой два.[_TT_1250] - А, даже, да.[_TT_1350] - Тердьон, хорошо, сможет.[_TT_1450][_BEG_] - А, я, конечно, да.[_TT_50] - Я когда-то работал, он был моим...[_TT_150] - Он был селк.[_TT_250] - А сейчас он, по-моему, будет другом месте работают два.[_TT_400] - Он сейчас саланец.[_TT_500] - Саланец.[_TT_550] - Да, очень хорошим.[_TT_600] - Мы с ним очень хорошей.[_TT_650] - Да, да, но не общались, но он с ним хорошей.[_TT_750] - А, что же ты?[_TT_800] - Хорошо, что ты.[_TT_850] - Хорошо, сейчас, он сейчас упсал, там с антидосновым.[_TT_1000] - Ммм.[_TT_1050] - Может быть, помор тем он больше, какой-то сейчас меня так показалось,[_TT_1200] - правило со самим, с тем, что он больше такой типа.[_TT_1300][_BEG_] - Нет, он все запустил, заполгал, я не пойду.[_TT_200] - А, ну, ладно.[_TT_300] - А, ваше я не верю, что он не нормально, нет,[_TT_450] - на смысле, у него все хорошо, мне, да, я не знаю,[_TT_550] - Вон, у него было, если он ваше, то тоже, то, что он не то самый.[_TT_700] - Я не верю, что он здесь.[_TT_800] - Спасибо, Фимин.[_TT_900] - Да, если он по моих виду.[_TT_1000] - Ваше, я не понимаю, я не понимаю, вообще, все.[_TT_1150] - А, ну, ну, ладно.[_TT_1200] - Да, он фаунда.[_TT_1250] - Без следы.[_TT_1300] - Он купил команду, конечно, по-моему, все бесплатно.[_TT_1450][_BEG_] - По-триком, бежен взаим, но я был уже когда,[_TT_150] - был я вот, когда, все расплатил,[_TT_300] - уже там был, как-то, в утреек, на донцах,[_TT_450] - и я только на конакт, ну, на серую команду,[_TT_650] - ну, на рынке, то ли, ну, спомнался,[_TT_750] - и еще еще, я так сделал антигенос,[_TT_900] - ну, я не знаю, я не в них как-то написал ни в течи кусок,[_TT_1050] - цвет, который, вот, он в звук, и все,[_TT_1150] - и вон есть там так, что он в сервис, вальсть.[_TT_1300] - Я вольственном фоне, вольсть, вольсть, вольсть.[_TT_1400][_BEG_] - Узелся это антигенос, вольсть, и,[_TT_150] - вольсть, и смотри, как, смотри, допомню,[_TT_300] - на коне сочной, все, все, все,[_TT_400] - и, с окрами, познакомились, мы пойгали.[_TT_550] - Так, он, недавно видел, по-траве,[_TT_700] - Да, да.[_TT_750] - Он, по-моему, некоспоргольчик не работает там.[_TT_850] - Да, да, и он, что-то, в сервис, так,[_TT_950] - где, вольсть, пинка,[_TT_1050]\n",
      "usage:  {'duration-seconds': 518.22, 'segments': 160, 'language': 'ru'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "response = model.inference(wav_file)\n",
    "\n",
    "print(\"\\nllm response: \", response[\"llm_response\"])\n",
    "print(\"usage: \", response[\"usage\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
