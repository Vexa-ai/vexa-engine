{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n",
      "Creating field-specific indices...\n",
      "Processing topic_name...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e05ce77fe38148b3906c00a050b4a195",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing summary...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a1b80e180e94d04a08f247e38e3ddc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing details...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65982cec941146d6b8a106802737dd1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sampling import fetch_joined_data\n",
    "df = await fetch_joined_data()\n",
    "df = df.sort_values(['meeting_timestamp'])\n",
    "from elastic_search import VectorSearchEngine\n",
    "search_engine = VectorSearchEngine(device=0)\n",
    "search_engine.create_index(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n",
      "Creating field-specific indices...\n",
      "Processing topic_name...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c299e1e31c674cf09a8b425e67ee8ea6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing summary...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ccf5739cc9d49ff842791ef6fcc6c0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing details...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa92a40431f5471496c027e3c5ec5fa8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting Iterative Research ===\n",
      "Initial Query: vexa\n",
      "Max Iterations: 5\n",
      "Target Context Quality: 0.8\n",
      "\n",
      "\n",
      "--- Iteration 1/5 ---\n",
      "Current Query: vexa\n",
      "Executing search...\n",
      "Found 119 results\n",
      "Generating report...\n",
      "\n",
      "Report Summary:\n",
      "- Context Quality: 0.85\n",
      "- Key Findings: 5\n",
      "- Information Gaps: 5\n",
      "- Follow-up Searches: 5\n",
      "\n",
      "Key Findings:\n",
      "1. Vexa is a real-time meeting assistant focused on transcription and contextual support.\n",
      "2. The product is in the pre-seed stage and is currently being tested with a developer version.\n",
      "3. User feedback is generally positive, but there are areas for improvement in usability and interface design.\n",
      "4. Marketing efforts are limited, with plans for influencer partnerships and community building.\n",
      "5. Future development includes a paid plan and potential collaborations to enhance product offerings.\n",
      "\n",
      "Added 5 new findings to cumulative context\n",
      "\n",
      "New High-Priority Follow-up Queries:\n",
      "1. Query: Vexa user demographics and target audience\n",
      "   Priority: 4\n",
      "   Rationale: Understanding the target audience will help tailor marketing strategies and product features to meet user needs.\n",
      "2. Query: Competitor analysis of Vexa in the meeting transcription market\n",
      "   Priority: 3\n",
      "   Rationale: Analyzing competitors will provide insights into Vexa's unique selling points and areas for improvement.\n",
      "3. Query: User engagement and retention metrics for Vexa\n",
      "   Priority: 4\n",
      "   Rationale: Gathering data on user engagement and retention will help assess the product's effectiveness and areas for enhancement.\n",
      "4. Query: Technology stack and architecture of Vexa\n",
      "   Priority: 3\n",
      "   Rationale: Understanding the technology behind Vexa will provide insights into its capabilities and potential for future development.\n",
      "5. Query: Feedback from users switching from competitors to Vexa\n",
      "   Priority: 4\n",
      "   Rationale: Collecting feedback from users who have transitioned from other tools will highlight Vexa's strengths and weaknesses in comparison.\n",
      "\n",
      "âœ“ Reached target context quality: 0.85\n",
      "\n",
      "=== Research Summary ===\n",
      "Completed Iterations: 1\n",
      "Total Queries Explored: 6\n",
      "Final Context Quality: 0.85\n",
      "Total Findings: 5\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "from iterative_research import conduct_iterative_research, SearchReport\n",
    "\n",
    "# Initialize search engine\n",
    "search_engine = VectorSearchEngine(device=0)\n",
    "search_engine.create_index(df)\n",
    "\n",
    "# Conduct research\n",
    "reports = await conduct_iterative_research(\n",
    "    search_engine=search_engine,\n",
    "    initial_query='vexa',\n",
    "    max_iterations=5,\n",
    "    min_context_quality=0.8,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Process results\n",
    "all_findings = []\n",
    "for report in reports:\n",
    "    all_findings.extend(report.key_findings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Vexa is a real-time meeting assistant focused on transcription and contextual support.',\n",
       " 'The product is in the pre-seed stage and is currently being tested with a developer version.',\n",
       " 'User feedback is generally positive, but there are areas for improvement in usability and interface design.',\n",
       " 'Marketing efforts are limited, with plans for influencer partnerships and community building.',\n",
       " 'Future development includes a paid plan and potential collaborations to enhance product offerings.']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
