{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Step 1 ===\n",
      "\n",
      "Search Plan:\n",
      "Steps: [\"Identify relevant variations of 'Vexa' and 'user feedback'\", 'Search for user feedback on Vexa', 'Analyze the results for insights on user opinions about Vexa']\n",
      "Current Filters: topic_type=None topic_name=['Vexa', 'VEXA', 'VEX.AI'] speaker_name=None date_range=None search_text='user feedback'\n",
      "Feedback: The initial search will focus on gathering user feedback specifically about Vexa, excluding coworker opinions. This will help in understanding the general sentiment and experiences of users with the product.\n",
      "\n",
      "Reflection:\n",
      "Sufficient: False\n",
      "Missing aspects: ['Specific user testimonials', 'Comparative analysis with competitors', 'User demographics']\n",
      "Quality Score: 0.4\n",
      "Key Findings: ['Initial search focused on user feedback for Vexa but needs refinement to exclude coworker insights.']\n",
      "Reasoning: The current results may not provide a comprehensive view of user feedback as they might include coworker opinions or lack specific user testimonials.\n",
      "\n",
      "Found 1 results in this step\n",
      "First step - using initial results\n",
      "\n",
      "New best results found! Score: 0.4\n",
      "\n",
      "=== Step 2 ===\n",
      "\n",
      "Search Plan:\n",
      "Steps: [\"Identify variations of 'users' and 'Vexa' in the context of user feedback.\", \"Search for user feedback specifically mentioning 'Vexa' or its features.\", 'Analyze the results for insights on user opinions about Vexa.']\n",
      "Current Filters: topic_type=['feedback', 'discussion', 'concern'] topic_name=['Vexa', 'VEXA', 'VEX.AI'] speaker_name=None date_range=None search_text='user feedback'\n",
      "Feedback: The current results are limited to a single entry that discusses Vexa as a product but does not provide user feedback. We need to broaden the search to capture more user perspectives and opinions on Vexa, especially from external users rather than coworkers.\n",
      "\n",
      "Reflection:\n",
      "Sufficient: False\n",
      "Missing aspects: ['User feedback from external sources', \"Diverse opinions on Vexa's features\", 'Comparative feedback with similar products']\n",
      "Quality Score: 0.2\n",
      "Key Findings: ['Current results focus on Vexa as a product but lack user feedback.', 'Need to capture external user opinions and experiences with Vexa.']\n",
      "Reasoning: The current results do not provide sufficient user feedback on Vexa. We need to expand the search to include more user-generated content and feedback from various sources.\n",
      "\n",
      "Found 0 results in this step\n",
      "Added 0 new unique results\n",
      "\n",
      "=== Step 3 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_395407/1211616517.py:223: FutureWarning: 'any' with datetime64 dtypes is deprecated and will raise in a future version. Use (obj != pd.Timestamp(0)).any() instead.\n",
      "  if df[col].apply(lambda x: isinstance(x, list)).any():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Search Plan:\n",
      "Steps: [\"Identify variations of 'Vexa' and 'user feedback'\", 'Search for user feedback on Vexa', 'Analyze results for relevance and completeness']\n",
      "Current Filters: topic_type=['product', 'feedback', 'discussion'] topic_name=['Vexa'] speaker_name=None date_range=None search_text='user feedback'\n",
      "Feedback: Searching for user feedback specifically about Vexa, excluding coworker opinions. The current results are limited, with only one entry related to Vexa. We need to broaden the search to capture more user perspectives.\n",
      "\n",
      "Found 1 results in this step\n",
      "Added 0 new unique results\n",
      "\n",
      "=== Step 4 ===\n",
      "\n",
      "Search Plan:\n",
      "Steps: [\"Identify variations of 'Vexa' and 'user feedback'\", 'Search for user feedback on Vexa', 'Analyze results for relevance and completeness', 'Determine if further searches are needed']\n",
      "Current Filters: topic_type=None topic_name=['Vexa'] speaker_name=None date_range=None search_text='user feedback'\n",
      "Feedback: Current results are limited to a single entry that discusses Vexa but does not provide user feedback specifically. We need to broaden the search to capture more user perspectives and experiences with Vexa.\n",
      "\n",
      "Found 1 results in this step\n",
      "Added 0 new unique results\n",
      "\n",
      "=== Step 5 ===\n",
      "\n",
      "Search Plan:\n",
      "Steps: [\"Identify variations of 'Vexa' and 'user feedback'\", 'Search for user feedback on Vexa', 'Analyze results for relevance and completeness', 'Determine if additional searches are needed']\n",
      "Current Filters: topic_type=None topic_name=['Vexa'] speaker_name=None date_range=None search_text='user feedback'\n",
      "Feedback: Current results are limited to a single entry that discusses Vexa but does not provide user feedback specifically. We need to broaden the search to capture more user perspectives and experiences with Vexa, not just internal discussions.\n",
      "\n",
      "Found 1 results in this step\n",
      "Added 0 new unique results\n",
      "\n",
      "Search stopped - reached maximum steps (5)\n",
      "\n",
      "Final Results: 1 total unique entries\n",
      "Best Quality Score: 0.4\n",
      "\n",
      "Key Findings Across Iterations:\n",
      "\n",
      "Step 1 (Score: 0.4):\n",
      "- Initial search focused on user feedback for Vexa but needs refinement to exclude coworker insights.\n",
      "\n",
      "Step 2 (Score: 0.2):\n",
      "- Current results focus on Vexa as a product but lack user feedback.\n",
      "- Need to capture external user opinions and experiences with Vexa.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from sampling import fetch_joined_data, WeightedSampler\n",
    "from core import BaseCall, system_msg, user_msg\n",
    "from pydantic import BaseModel, Field\n",
    "from datetime import datetime\n",
    "from typing import Optional, List\n",
    "\n",
    "# Fetch and prepare data\n",
    "joined_df = await fetch_joined_data()\n",
    "joined_df['meeting_time'] = pd.to_datetime(joined_df['meeting_timestamp']).dt.strftime('%Y-%m-%d')\n",
    "\n",
    "sampler = WeightedSampler(joined_df, date_column='meeting_time', decay_factor=0.2)\n",
    "sampled_redults = sampler.sample(n_samples=100)  # mode defaults to 'recency'\n",
    "\n",
    "def get_unique_value_counts(df, columns, format_output=False):\n",
    "    \"\"\"\n",
    "    Returns unique values and their counts for specified columns.\n",
    "    \"\"\"\n",
    "    result = {}\n",
    "    \n",
    "    for col in columns:\n",
    "        try:\n",
    "            value_counts = df[col].value_counts()\n",
    "            value_dict_list = [{'value': value, 'count': count} \n",
    "                             for value, count in value_counts.items()]\n",
    "            result[col] = value_dict_list\n",
    "        except (TypeError, AttributeError):\n",
    "            value_counts = df[col].astype(str).value_counts()\n",
    "            value_dict_list = [{'value': value, 'count': count} \n",
    "                             for value, count in value_counts.items()]\n",
    "            result[col] = value_dict_list\n",
    "    \n",
    "    if format_output:\n",
    "        output_str = \"\"\n",
    "        for col, value_list in result.items():\n",
    "            output_str += f\"\\n{col}:\\n\"\n",
    "            for item in value_list:\n",
    "                output_str += f\"  {item['value']}: {item['count']}\\n\"\n",
    "        return output_str.strip()\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Get formatted string result for context\n",
    "str_result = get_unique_value_counts(joined_df, ['topic_type', 'topic_name', 'speaker_name'], format_output=True)\n",
    "\n",
    "class DateRange(BaseModel):\n",
    "    start_date: Optional[datetime] = Field(None, description=\"Start date of the range\")\n",
    "    end_date: Optional[datetime] = Field(None, description=\"End date of the range\")\n",
    "\n",
    "class SearchFilter(BaseModel):\n",
    "    topic_type: Optional[List[str]] = Field(None, description=\"List of topic types to filter by\")\n",
    "    topic_name: Optional[List[str]] = Field(None, description=\"List of topic names to filter by\")\n",
    "    speaker_name: Optional[List[str]] = Field(None, description=\"List of speaker names to filter by\")\n",
    "    date_range: Optional[DateRange] = Field(None, description=\"Date range to filter by\")\n",
    "    search_text: Optional[str] = Field(None, description=\"Text to search for in summary and details columns using similarity search\")\n",
    "\n",
    "def apply_search_filters(df: pd.DataFrame, filters: SearchFilter) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Apply SearchFilter parameters to filter a DataFrame.\n",
    "    \"\"\"\n",
    "    filtered_df = df.copy()\n",
    "    \n",
    "    if filters.topic_type:\n",
    "        filtered_df = filtered_df[filtered_df['topic_type'].isin(filters.topic_type)]\n",
    "    \n",
    "    if filters.topic_name:\n",
    "        filtered_df = filtered_df[filtered_df['topic_name'].isin(filters.topic_name)]\n",
    "        \n",
    "    if filters.speaker_name:\n",
    "        filtered_df = filtered_df[filtered_df['speaker_name'].isin(filters.speaker_name)]\n",
    "    \n",
    "    if filters.date_range:\n",
    "        if filters.date_range.start_date:\n",
    "            filtered_df = filtered_df[\n",
    "                pd.to_datetime(filtered_df['meeting_time']) >= filters.date_range.start_date\n",
    "            ]\n",
    "        if filters.date_range.end_date:\n",
    "            filtered_df = filtered_df[\n",
    "                pd.to_datetime(filtered_df['meeting_time']) <= filters.date_range.end_date\n",
    "            ]\n",
    "    \n",
    "    if filters.search_text:\n",
    "        text_mask = (\n",
    "            filtered_df['summary'].str.contains(filters.search_text, case=False, na=False) |\n",
    "            filtered_df['details'].str.contains(filters.search_text, case=False, na=False)\n",
    "        )\n",
    "        filtered_df = filtered_df[text_mask]\n",
    "    \n",
    "    return filtered_df\n",
    "\n",
    "class SearchReflection(BaseModel):\n",
    "    is_sufficient: bool = Field(..., description=\"Whether current results are sufficient to answer the user query\")\n",
    "    missing_aspects: List[str] = Field(..., description=\"List of aspects still missing from the results\")\n",
    "    suggested_filters: Optional[SearchFilter] = Field(None, description=\"Suggested additional filters if needed\")\n",
    "    reasoning: str = Field(..., description=\"Explanation of why results are/aren't sufficient\")\n",
    "    quality_score: float = Field(..., ge=0, le=1, description=\"Score indicating how well these results answer the query (0-1)\")\n",
    "    key_findings: List[str] = Field(..., description=\"List of key insights found in current results\")\n",
    "\n",
    "class SearchPlan(BaseModel):\n",
    "    steps: List[str] = Field(..., description=\"List of search steps to execute\")\n",
    "    current_filters: SearchFilter = Field(..., description=\"Current step search parameters\")\n",
    "    is_final: bool = Field(..., description=\"Whether this is the final search step\")\n",
    "    feedback: str = Field(..., description=\"Analysis of current results and next steps needed\")\n",
    "    reflection: Optional[SearchReflection] = Field(None, description=\"Reflection on search results quality\")\n",
    "\n",
    "class SearchParams(BaseCall):\n",
    "    plan: SearchPlan = Field(..., description=\"Search plan with current step and feedback\")\n",
    "    \n",
    "    @classmethod\n",
    "    async def extract(cls, user_query: str, table_context: str, sampled_df: pd.DataFrame, \n",
    "                     previous_results: Optional[pd.DataFrame] = None, \n",
    "                     current_results: Optional[pd.DataFrame] = None,\n",
    "                     step_number: int = 1,\n",
    "                     model: str = \"gpt-4o-mini\", \n",
    "                     use_cache: bool = False, \n",
    "                     force_store: bool = False):\n",
    "        current_time = datetime.now()\n",
    "        \n",
    "        # Convert sampled results to a readable format\n",
    "        sample_context = f\"\"\"Sample of recent records:\n",
    "{sampled_df[['meeting_time', 'topic_type', 'topic_name', 'speaker_name']].head().to_markdown()}\n",
    "\"\"\"\n",
    "        \n",
    "        # Add current results context if available\n",
    "        results_context = \"\"\n",
    "        if current_results is not None:\n",
    "            results_context = f\"\"\"\n",
    "Current search results:\n",
    "{current_results[['meeting_time', 'topic_type', 'topic_name', 'speaker_name', 'summary']].head().to_markdown()}\n",
    "Total results: {len(current_results)} entries\n",
    "\"\"\"\n",
    "        \n",
    "        output = await cls.call([\n",
    "            system_msg(\"\"\"Plan and execute a multi-step search strategy to thoroughly answer the user's query.\n",
    "                      Use the provided table context to identify and handle variations and possible misspellings.\n",
    "                      \n",
    "                      For each step:\n",
    "                      1. Check the table context for all relevant variations of search terms\n",
    "                      2. Include all valid variations in the search filters\n",
    "                      3. Analyze current results if available\n",
    "                      4. Reflect on whether results are sufficient to answer the query\n",
    "                      5. Determine if additional search steps are needed\n",
    "                      \n",
    "                      When reflecting on results, consider:\n",
    "                      - Do we have enough context about all mentioned entities?\n",
    "                      - Are we capturing all relevant time periods?\n",
    "                      - Have we found all important perspectives/opinions?\n",
    "                      - Are the results specific enough to answer the query?\n",
    "                      - Would additional filters help focus the results?\n",
    "                      \n",
    "                      Provide a quality score (0-1) based on:\n",
    "                      - Relevance to the query\n",
    "                      - Completeness of the answer\n",
    "                      - Specificity of the results\n",
    "                      - Coverage of different aspects\n",
    "                      \n",
    "                      Include key findings that summarize what we've learned from the results.\"\"\"),\n",
    "            user_msg(f\"\"\"Current datetime: {current_time}\n",
    "\n",
    "Table context showing available values:\n",
    "{table_context}\n",
    "\n",
    "{sample_context}\n",
    "{results_context}\n",
    "\n",
    "User query: {user_query}\n",
    "Current step: {step_number}\n",
    "\n",
    "Plan the search strategy and reflect on current results.\"\"\")\n",
    "        ], model=model, use_cache=use_cache, force_store=force_store)\n",
    "        \n",
    "        return output[0].plan\n",
    "\n",
    "async def iterative_search(query: str, joined_df: pd.DataFrame, context: str, sampled_df: pd.DataFrame, verbose: bool = True):\n",
    "    all_iterations = []  # Store all iteration results and their reflections\n",
    "    results = None\n",
    "    step = 1\n",
    "    best_score = 0\n",
    "    best_results = None\n",
    "    \n",
    "    while True:\n",
    "        if verbose:\n",
    "            print(f\"\\n=== Step {step} ===\")\n",
    "            \n",
    "        # Get search plan for current step\n",
    "        search_plan = await SearchParams.extract(\n",
    "            user_query=query,\n",
    "            table_context=context,\n",
    "            sampled_df=sampled_df,\n",
    "            previous_results=results,\n",
    "            current_results=results,  # Pass current results for reflection\n",
    "            step_number=step\n",
    "        )\n",
    "        \n",
    "        if verbose:\n",
    "            print(\"\\nSearch Plan:\")\n",
    "            print(f\"Steps: {search_plan.steps}\")\n",
    "            print(f\"Current Filters: {search_plan.current_filters}\")\n",
    "            print(f\"Feedback: {search_plan.feedback}\")\n",
    "            if search_plan.reflection:\n",
    "                print(\"\\nReflection:\")\n",
    "                print(f\"Sufficient: {search_plan.reflection.is_sufficient}\")\n",
    "                print(f\"Missing aspects: {search_plan.reflection.missing_aspects}\")\n",
    "                print(f\"Quality Score: {search_plan.reflection.quality_score}\")\n",
    "                print(f\"Key Findings: {search_plan.reflection.key_findings}\")\n",
    "                print(f\"Reasoning: {search_plan.reflection.reasoning}\")\n",
    "        \n",
    "        # Apply current filters\n",
    "        current_results = apply_search_filters(joined_df, search_plan.current_filters)\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"\\nFound {len(current_results)} results in this step\")\n",
    "        \n",
    "        # Update results - handle list columns by converting to tuples\n",
    "        if results is None:\n",
    "            results = current_results\n",
    "            if verbose:\n",
    "                print(\"First step - using initial results\")\n",
    "        else:\n",
    "            # Convert list columns to tuples for both DataFrames\n",
    "            for df in [results, current_results]:\n",
    "                for col in df.columns:\n",
    "                    if df[col].apply(lambda x: isinstance(x, list)).any():\n",
    "                        df[col] = df[col].apply(lambda x: tuple(x) if isinstance(x, list) else x)\n",
    "            \n",
    "            old_len = len(results)\n",
    "            results = pd.concat([results, current_results]).drop_duplicates()\n",
    "            new_len = len(results)\n",
    "            \n",
    "            if verbose:\n",
    "                print(f\"Added {new_len - old_len} new unique results\")\n",
    "        \n",
    "        # Store current iteration results and reflection\n",
    "        if search_plan.reflection:\n",
    "            iteration_info = {\n",
    "                'step': step,\n",
    "                'results': results.copy(),\n",
    "                'reflection': search_plan.reflection,\n",
    "                'filters': search_plan.current_filters,\n",
    "                'quality_score': search_plan.reflection.quality_score\n",
    "            }\n",
    "            all_iterations.append(iteration_info)\n",
    "            \n",
    "            # Update best results if current score is higher\n",
    "            if search_plan.reflection.quality_score > best_score:\n",
    "                best_score = search_plan.reflection.quality_score\n",
    "                best_results = results.copy()\n",
    "                \n",
    "                if verbose:\n",
    "                    print(f\"\\nNew best results found! Score: {best_score}\")\n",
    "        \n",
    "        # Check if we're done based on reflection\n",
    "        if search_plan.reflection and search_plan.reflection.is_sufficient:\n",
    "            if verbose:\n",
    "                print(\"\\nSearch complete - results deemed sufficient\")\n",
    "            break\n",
    "            \n",
    "        step += 1\n",
    "        if step > 5:  # Safety limit\n",
    "            if verbose:\n",
    "                print(\"\\nSearch stopped - reached maximum steps (5)\")\n",
    "            break\n",
    "    \n",
    "    # Use best results found during iterations\n",
    "    results = best_results if best_results is not None else results\n",
    "    \n",
    "    # Convert tuple columns back to lists in final results\n",
    "    for col in results.columns:\n",
    "        if results[col].apply(lambda x: isinstance(x, tuple)).any():\n",
    "            results[col] = results[col].apply(lambda x: list(x) if isinstance(x, tuple) else x)\n",
    "    \n",
    "    # Calculate relevance scores and sort results\n",
    "    search_terms = set([term.lower() for term in query.split()])\n",
    "    \n",
    "    def calculate_relevance(row):\n",
    "        text = f\"{row['summary']} {row['details']}\".lower()\n",
    "        # Count occurrences of search terms\n",
    "        term_matches = sum(text.count(term) for term in search_terms)\n",
    "        # Boost score for more recent dates\n",
    "        recency_boost = pd.to_datetime(row['meeting_time']).timestamp() / 1e9\n",
    "        return term_matches + (recency_boost / 1e11)  # Normalize recency boost\n",
    "    \n",
    "    results['relevance_score'] = results.apply(calculate_relevance, axis=1)\n",
    "    results = results.sort_values('relevance_score', ascending=False).drop(columns=['relevance_score'])\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"\\nFinal Results: {len(results)} total unique entries\")\n",
    "        print(f\"Best Quality Score: {best_score}\")\n",
    "        print(\"\\nKey Findings Across Iterations:\")\n",
    "        for iteration in all_iterations:\n",
    "            print(f\"\\nStep {iteration['step']} (Score: {iteration['quality_score']}):\")\n",
    "            for finding in iteration['reflection'].key_findings:\n",
    "                print(f\"- {finding}\")\n",
    "    \n",
    "    return results, all_iterations\n",
    "\n",
    "# Example usage\n",
    "results, search_history = await iterative_search(\n",
    "    query=\"what users say about vexa, not covorkers\",\n",
    "    joined_df=joined_df,\n",
    "    context=str_result,\n",
    "    sampled_df=sampled_redults,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>summary_index</th>\n",
       "      <th>summary</th>\n",
       "      <th>details</th>\n",
       "      <th>referenced_text</th>\n",
       "      <th>topic_name</th>\n",
       "      <th>topic_type</th>\n",
       "      <th>meeting_id</th>\n",
       "      <th>meeting_timestamp</th>\n",
       "      <th>speaker_name</th>\n",
       "      <th>other_speakers</th>\n",
       "      <th>meeting_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>676</th>\n",
       "      <td>6</td>\n",
       "      <td>Vexa is a product discussed in the meeting, fo...</td>\n",
       "      <td>Vexa is currently in the testing phase with a ...</td>\n",
       "      <td>Dmitry Grankin:  Yeah, we went on marketing, b...</td>\n",
       "      <td>Vexa</td>\n",
       "      <td>product</td>\n",
       "      <td>70cd7290-801a-4caf-9786-359cc6e16c60</td>\n",
       "      <td>2024-09-30 10:01:22.780</td>\n",
       "      <td>Dmitry Grankin</td>\n",
       "      <td>[Umar Lateef]</td>\n",
       "      <td>2024-09-30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     summary_index                                            summary  \\\n",
       "676              6  Vexa is a product discussed in the meeting, fo...   \n",
       "\n",
       "                                               details  \\\n",
       "676  Vexa is currently in the testing phase with a ...   \n",
       "\n",
       "                                       referenced_text topic_name topic_type  \\\n",
       "676  Dmitry Grankin:  Yeah, we went on marketing, b...       Vexa    product   \n",
       "\n",
       "                               meeting_id       meeting_timestamp  \\\n",
       "676  70cd7290-801a-4caf-9786-359cc6e16c60 2024-09-30 10:01:22.780   \n",
       "\n",
       "       speaker_name other_speakers meeting_time  \n",
       "676  Dmitry Grankin  [Umar Lateef]   2024-09-30  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic_type=None topic_name=['Vexa', 'VEXA', 'VEX.AI'] speaker_name=None date_range=None search_text='user feedback'\n",
      "is_sufficient=False missing_aspects=['Specific user testimonials', 'Comparative analysis with competitors', 'User demographics'] suggested_filters=SearchFilter(topic_type=['feedback', 'discussion', 'concern'], topic_name=None, speaker_name=None, date_range=None, search_text=None) reasoning='The current results may not provide a comprehensive view of user feedback as they might include coworker opinions or lack specific user testimonials.' quality_score=0.4 key_findings=['Initial search focused on user feedback for Vexa but needs refinement to exclude coworker insights.']\n",
      "topic_type=['feedback', 'discussion', 'concern'] topic_name=['Vexa', 'VEXA', 'VEX.AI'] speaker_name=None date_range=None search_text='user feedback'\n",
      "is_sufficient=False missing_aspects=['User feedback from external sources', \"Diverse opinions on Vexa's features\", 'Comparative feedback with similar products'] suggested_filters=SearchFilter(topic_type=['feedback', 'discussion', 'concern'], topic_name=['Vexa', 'VEXA', 'VEX.AI'], speaker_name=None, date_range=None, search_text=None) reasoning='The current results do not provide sufficient user feedback on Vexa. We need to expand the search to include more user-generated content and feedback from various sources.' quality_score=0.2 key_findings=['Current results focus on Vexa as a product but lack user feedback.', 'Need to capture external user opinions and experiences with Vexa.']\n"
     ]
    }
   ],
   "source": [
    "for step in search_history:\n",
    "    print(step['filters'])\n",
    "    print(step['reflection'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>summary_index</th>\n",
       "      <th>summary</th>\n",
       "      <th>details</th>\n",
       "      <th>referenced_text</th>\n",
       "      <th>topic_name</th>\n",
       "      <th>topic_type</th>\n",
       "      <th>meeting_id</th>\n",
       "      <th>meeting_timestamp</th>\n",
       "      <th>speaker_name</th>\n",
       "      <th>other_speakers</th>\n",
       "      <th>meeting_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>676</th>\n",
       "      <td>6</td>\n",
       "      <td>Vexa is a product discussed in the meeting, fo...</td>\n",
       "      <td>Vexa is currently in the testing phase with a ...</td>\n",
       "      <td>Dmitry Grankin:  Yeah, we went on marketing, b...</td>\n",
       "      <td>Vexa</td>\n",
       "      <td>product</td>\n",
       "      <td>70cd7290-801a-4caf-9786-359cc6e16c60</td>\n",
       "      <td>2024-09-30 10:01:22.780</td>\n",
       "      <td>Dmitry Grankin</td>\n",
       "      <td>(Umar Lateef,)</td>\n",
       "      <td>2024-09-30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     summary_index                                            summary  \\\n",
       "676              6  Vexa is a product discussed in the meeting, fo...   \n",
       "\n",
       "                                               details  \\\n",
       "676  Vexa is currently in the testing phase with a ...   \n",
       "\n",
       "                                       referenced_text topic_name topic_type  \\\n",
       "676  Dmitry Grankin:  Yeah, we went on marketing, b...       Vexa    product   \n",
       "\n",
       "                               meeting_id       meeting_timestamp  \\\n",
       "676  70cd7290-801a-4caf-9786-359cc6e16c60 2024-09-30 10:01:22.780   \n",
       "\n",
       "       speaker_name  other_speakers meeting_time  \n",
       "676  Dmitry Grankin  (Umar Lateef,)   2024-09-30  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step['results']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SearchReflection(is_sufficient=False, missing_aspects=['User feedback from external sources', \"Diverse opinions on Vexa's features\", 'Comparative feedback with similar products'], suggested_filters=SearchFilter(topic_type=['feedback', 'discussion', 'concern'], topic_name=['Vexa', 'VEXA', 'VEX.AI'], speaker_name=None, date_range=None, search_text=None), reasoning='The current results do not provide sufficient user feedback on Vexa. We need to expand the search to include more user-generated content and feedback from various sources.', quality_score=0.2, key_findings=['Current results focus on Vexa as a product but lack user feedback.', 'Need to capture external user opinions and experiences with Vexa.'])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step['reflection']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>summary_index</th>\n",
       "      <th>summary</th>\n",
       "      <th>details</th>\n",
       "      <th>referenced_text</th>\n",
       "      <th>topic_name</th>\n",
       "      <th>topic_type</th>\n",
       "      <th>meeting_id</th>\n",
       "      <th>meeting_timestamp</th>\n",
       "      <th>speaker_name</th>\n",
       "      <th>other_speakers</th>\n",
       "      <th>meeting_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>676</th>\n",
       "      <td>6</td>\n",
       "      <td>Vexa is a product discussed in the meeting, fo...</td>\n",
       "      <td>Vexa is currently in the testing phase with a ...</td>\n",
       "      <td>Dmitry Grankin:  Yeah, we went on marketing, b...</td>\n",
       "      <td>Vexa</td>\n",
       "      <td>product</td>\n",
       "      <td>70cd7290-801a-4caf-9786-359cc6e16c60</td>\n",
       "      <td>2024-09-30 10:01:22.780</td>\n",
       "      <td>Dmitry Grankin</td>\n",
       "      <td>[Umar Lateef]</td>\n",
       "      <td>2024-09-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>676</th>\n",
       "      <td>6</td>\n",
       "      <td>Vexa is a product discussed in the meeting, fo...</td>\n",
       "      <td>Vexa is currently in the testing phase with a ...</td>\n",
       "      <td>Dmitry Grankin:  Yeah, we went on marketing, b...</td>\n",
       "      <td>Vexa</td>\n",
       "      <td>product</td>\n",
       "      <td>70cd7290-801a-4caf-9786-359cc6e16c60</td>\n",
       "      <td>2024-09-30 10:01:22.780</td>\n",
       "      <td>Dmitry Grankin</td>\n",
       "      <td>(Umar Lateef,)</td>\n",
       "      <td>2024-09-30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     summary_index                                            summary  \\\n",
       "676              6  Vexa is a product discussed in the meeting, fo...   \n",
       "676              6  Vexa is a product discussed in the meeting, fo...   \n",
       "\n",
       "                                               details  \\\n",
       "676  Vexa is currently in the testing phase with a ...   \n",
       "676  Vexa is currently in the testing phase with a ...   \n",
       "\n",
       "                                       referenced_text topic_name topic_type  \\\n",
       "676  Dmitry Grankin:  Yeah, we went on marketing, b...       Vexa    product   \n",
       "676  Dmitry Grankin:  Yeah, we went on marketing, b...       Vexa    product   \n",
       "\n",
       "                               meeting_id       meeting_timestamp  \\\n",
       "676  70cd7290-801a-4caf-9786-359cc6e16c60 2024-09-30 10:01:22.780   \n",
       "676  70cd7290-801a-4caf-9786-359cc6e16c60 2024-09-30 10:01:22.780   \n",
       "\n",
       "       speaker_name  other_speakers meeting_time  \n",
       "676  Dmitry Grankin   [Umar Lateef]   2024-09-30  \n",
       "676  Dmitry Grankin  (Umar Lateef,)   2024-09-30  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([step['results'] for step in search_history])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
