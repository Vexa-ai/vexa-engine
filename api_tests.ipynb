{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vexa token: 3ae04e20124d40babc5107e658c666b6\n",
      "User information retrieved successfully.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "from datetime import datetime\n",
    "from typing import Optional, List, Dict, Any, Generator\n",
    "\n",
    "\n",
    "from vexa import VexaAPI\n",
    "vexa = VexaAPI()\n",
    "await vexa.get_user_info()\n",
    "\n",
    "BASE_URL = \"http://localhost:8765\"\n",
    "headers = {\"Authorization\": f\"Bearer {vexa.token}\", \"Content-Type\": \"application/json\"}\n",
    "\n",
    "def submit_token(token: str) -> Dict:\n",
    "    return requests.post(f\"{BASE_URL}/submit_token\", json={\"token\": token}).json()\n",
    "\n",
    "def chat(query: str, thread_id: Optional[str] = None, model: str = \"gpt-4o-mini\", temperature: float = 0.7) -> Dict:\n",
    "    response = requests.post(f\"{BASE_URL}/chat\", headers=headers, json={\n",
    "        \"query\": query, \"thread_id\": thread_id, \"model\": model, \"temperature\": temperature\n",
    "    }, stream=True)\n",
    "    \n",
    "    final_response = None\n",
    "    for line in response.iter_lines():\n",
    "        if line:\n",
    "            try:\n",
    "                data = json.loads(line.decode('utf-8').replace('data: ', ''))\n",
    "                if data.get('type') == 'stream':\n",
    "                    print(data.get('content', ''), end='', flush=True)\n",
    "                elif data.get('type') == 'done':\n",
    "                    break\n",
    "                else:\n",
    "                    final_response = data\n",
    "            except json.JSONDecodeError:\n",
    "                continue\n",
    "    \n",
    "    return final_response or {\"error\": \"No response received\"}\n",
    "def global_search(query: str, limit: int = 200, min_score: float = 0.4) -> Dict:\n",
    "    return requests.post(f\"{BASE_URL}/search/global\", headers=headers, \n",
    "        json={\"query\": query, \"limit\": limit, \"min_score\": min_score}).json()\n",
    "\n",
    "def search_transcripts(query: str, meeting_ids: Optional[List[str]] = None, min_score: float = 0.8) -> Dict:\n",
    "    return requests.post(f\"{BASE_URL}/search/transcripts\", headers=headers,\n",
    "        json={\"query\": query, \"meeting_ids\": meeting_ids, \"min_score\": min_score}).json()\n",
    "\n",
    "def get_meetings(offset: int = 0, limit: int = 50) -> Dict:\n",
    "    return requests.get(f\"{BASE_URL}/meetings/all\", headers=headers, \n",
    "        params={\"offset\": offset, \"limit\": limit}).json()\n",
    "\n",
    "def get_meeting_details(meeting_id: str) -> Dict:\n",
    "    return requests.get(f\"{BASE_URL}/meeting/{meeting_id}/details\", headers=headers).json()\n",
    "\n",
    "def create_share_link(target_email: str, access_level: str = \"READ\", \n",
    "                     expiration_hours: int = 24, include_existing: bool = True) -> Dict:\n",
    "    return requests.post(f\"{BASE_URL}/share-links\", headers=headers, json={\n",
    "        \"access_level\": access_level, \"target_email\": target_email,\n",
    "        \"expiration_hours\": expiration_hours, \"include_existing_meetings\": include_existing\n",
    "    }).json()\n",
    "\n",
    "def accept_share_link(token: str, accepting_email: str) -> Dict:\n",
    "    return requests.post(f\"{BASE_URL}/share-links/accept\", headers=headers,\n",
    "        json={\"token\": token, \"accepting_email\": accepting_email}).json()\n",
    "\n",
    "def start_indexing(num_meetings: int = 200) -> Dict:\n",
    "    return requests.post(f\"{BASE_URL}/start_indexing\", headers=headers,\n",
    "        json={\"num_meetings\": num_meetings}).json()\n",
    "\n",
    "def get_indexing_status() -> Dict:\n",
    "    return requests.get(f\"{BASE_URL}/indexing_status\", headers=headers).json()\n",
    "\n",
    "# Add these functions to the initialization cell with other API functions\n",
    "def get_threads(meeting_id: Optional[str] = None) -> Dict:\n",
    "    \"\"\"Get threads for global or meeting-specific context\"\"\"\n",
    "    if meeting_id:\n",
    "        return requests.get(f\"{BASE_URL}/threads/{meeting_id}\", headers=headers).json()\n",
    "    return requests.get(f\"{BASE_URL}/threads\", headers=headers).json()\n",
    "\n",
    "def delete_thread(thread_id: str) -> Dict:\n",
    "    return requests.delete(f\"{BASE_URL}/thread/{thread_id}\", headers=headers).json()\n",
    "\n",
    "def chat_meeting(\n",
    "    query: str, \n",
    "    meeting_ids: List[str], \n",
    "    thread_id: Optional[str] = None, \n",
    "    model: str = \"gpt-4o-mini\", \n",
    "    temperature: float = 0.7\n",
    ") -> Dict:\n",
    "    response = requests.post(\n",
    "        f\"{BASE_URL}/chat/meeting\", \n",
    "        headers=headers, \n",
    "        json={\n",
    "            \"query\": query,\n",
    "            \"meeting_ids\": meeting_ids,\n",
    "            \"thread_id\": thread_id,\n",
    "            \"model\": model,\n",
    "            \"temperature\": temperature\n",
    "        },\n",
    "        stream=True\n",
    "    )\n",
    "    \n",
    "    final_response = None\n",
    "    for line in response.iter_lines():\n",
    "        if line:\n",
    "            try:\n",
    "                data = json.loads(line.decode('utf-8').replace('data: ', ''))\n",
    "                if data.get('type') == 'stream':\n",
    "                    print(data.get('content', ''), end='', flush=True)\n",
    "                elif data.get('type') == 'done':\n",
    "                    break\n",
    "                else:\n",
    "                    final_response = data\n",
    "            except json.JSONDecodeError:\n",
    "                continue\n",
    "    \n",
    "    return final_response or {\"error\": \"No response received\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dmitriy Grankin has been actively involved in various discussions and projects, focusing on the development of tools and systems aimed at improving efficiency and accessibility in meetings and legal processes. Below are key highlights of his contributions:\n",
      "\n",
      "### Key Contributions\n",
      "\n",
      "- **API Development**: Completed the development of an API for integration with frontend systems, enhancing functionality and user interaction[1][4].\n",
      "  \n",
      "- **Frontend Development**: Actively working on the frontend for a project that interacts with the API, addressing functionality and usability issues[1][4].\n",
      "\n",
      "- **Testing LAMA 3.2**: Conducted tests on the LAMA 3.2 model, which has 90 billion parameters, showing promising results but requiring further refinement for project use[1][4].\n",
      "\n",
      "- **Knowledge Base Creation**: Finalized the delivery of a knowledge base compiling information from Google Meet calls, making it accessible for future reference and use[2][4].\n",
      "\n",
      "- **Search Capabilities Implementation**: Researched and implemented search capabilities to enhance access to meeting details, allowing for specific inquiries related to discussions[2][4].\n",
      "\n",
      "- **Meeting Recording System Development**: Introduced a new system that converts spoken words from meetings into accessible knowledge, facilitating unlimited recordings and improving report generation[7][4].\n",
      "\n",
      "- **Integration of AI in Legal Processes**: Discussed the potential of integrating AI services to enhance legal documentation and processes, focusing on the needs of legal professionals[8][4].\n",
      "\n",
      "- **Challenges in Code and Performance**: Engaged in discussions about code quality and performance improvements, particularly in the context of developing the Vexa Multi Assistant[9][4].\n",
      "\n",
      "### Recent Discussions\n",
      "\n",
      "- **Marketing Strategies**: Identified email marketing as a task to be addressed, indicating a focus on enhancing outreach efforts[14][4].\n",
      "\n",
      "- **Cloud Transition**: Emphasized the necessity of transitioning services to cloud platforms for improved reliability and accessibility[13][4].\n",
      "\n",
      "- **User Retention and Product Development**: Reported steady user retention and ongoing development of features based on user feedback, indicating a positive outlook for the product[5][4].\n",
      "\n",
      "Dmitriy Grankin's work reflects a strong commitment to enhancing technological solutions in both development and legal contexts, with a focus on usability, efficiency, and integration of advanced technologies."
     ]
    }
   ],
   "source": [
    "r =chat('dmitry')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Встреча была посвящена переходу на новый dashboard и интеграции с маркетингом. Основные обсуждаемые темы включали:\n",
      "\n",
      "1. Необходимость наличия нормального локального счета и поиска summary и индекса для успешного перехода на новый dashboard.\n",
      "2. Отладка системы Threads и создание контекстного summary из глобального контекста.\n",
      "3. Планы по интеграции с email-маркетингом и календарями, а также выпуск хотя бы одного поста по маркетингу.\n",
      "4. Обсуждение возможности переноса локального серчборда и необходимость использования более широкого контекста для векторного поиска.\n",
      "\n",
      "В целом, встреча сосредоточена на улучшении функциональности и интеграции различных систем для повышения эффективности работы."
     ]
    }
   ],
   "source": [
    "r = chat_meeting('о чем встреча?', ['ab27bb1f-93d5-4500-9865-6f5de4d433ea'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'thread_id': '269f19f0-ef3f-46aa-9adb-d28d4910bfdd',\n",
       " 'service_content': {'context_source': 'meeting',\n",
       "  'meeting_count': 1,\n",
       "  'meeting_id': 'ab27bb1f-93d5-4500-9865-6f5de4d433ea'}}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
