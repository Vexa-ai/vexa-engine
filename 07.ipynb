{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "       # Don't wrap wide columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from psql_models import read_table_async,DiscussionPoint,Meeting,Speaker,Output\n",
    "from pydantic_models import MeetingSummary\n",
    "import string\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "# Set display options to show all content\n",
    "pd.set_option('display.max_colwidth', 100)  # Show full contents of each column\n",
    "pd.set_option('display.max_rows', 20)      # Show all rows\n",
    "pd.set_option('display.max_columns', 20)   # Show all columns\n",
    "pd.set_option('display.width', 100)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "discussion_points_df = await read_table_async(DiscussionPoint)\n",
    "meetings_df = await read_table_async(Meeting)\n",
    "speakers_df = await read_table_async(Speaker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... existing code ...\n",
    "\n",
    "from sqlalchemy import select\n",
    "from psql_models import async_session, DiscussionPoint, Meeting, Speaker\n",
    "\n",
    "async def fetch_joined_data():\n",
    "    async with async_session() as session:\n",
    "        # Original query remains the same\n",
    "        query = select(DiscussionPoint, Meeting, Speaker).join(\n",
    "            Meeting, DiscussionPoint.meeting_id == Meeting.meeting_id\n",
    "        ).join(\n",
    "            Speaker, DiscussionPoint.speaker_id == Speaker.id\n",
    "        )\n",
    "        \n",
    "        result = await session.execute(query)\n",
    "        rows = result.fetchall()\n",
    "        \n",
    "        # Create a dictionary to store all speakers per meeting\n",
    "        meeting_speakers = {}\n",
    "        for dp, meeting, speaker in rows:\n",
    "            if meeting.meeting_id not in meeting_speakers:\n",
    "                meeting_speakers[meeting.meeting_id] = set()\n",
    "            meeting_speakers[meeting.meeting_id].add(speaker.name)\n",
    "        \n",
    "        # Convert the result to a list of dictionaries with other speakers\n",
    "        data = []\n",
    "        for dp, meeting, speaker in rows:\n",
    "            # Get all speakers except the current one\n",
    "            other_speakers = list(meeting_speakers[meeting.meeting_id] - {speaker.name})\n",
    "            \n",
    "            data.append({\n",
    "                # Original fields remain the same\n",
    "                'summary_index': dp.summary_index,\n",
    "                'summary': dp.summary,\n",
    "                'details': dp.details,\n",
    "                'referenced_text': dp.referenced_text,\n",
    "                'topic_name': dp.topic_name,\n",
    "                'topic_type': dp.topic_type,\n",
    "                'meeting_id': meeting.meeting_id,\n",
    "                'meeting_timestamp': meeting.timestamp,\n",
    "                'speaker_name': speaker.name,\n",
    "                # Add new field\n",
    "                'other_speakers': other_speakers\n",
    "            })\n",
    "\n",
    "        df = pd.DataFrame(data)\n",
    "        return df\n",
    "\n",
    "# Fetch the joined data\n",
    "joined_df = await fetch_joined_data()\n",
    "joined_df = joined_df.sort_values(by='meeting_timestamp').reset_index(drop=True)\n",
    "\n",
    "joined_df['meeting_time'] = pd.to_datetime(joined_df['meeting_timestamp']).dt.strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3194"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(joined_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request URL: http://127.0.0.1:8001/api/v1/calls/all\n",
      "Request Params: {'token': '3ae04e20124d40babc5107e658c666b6'}\n"
     ]
    }
   ],
   "source": [
    "from vexa import VexaAPI\n",
    "vexa = VexaAPI()\n",
    "meetings = await vexa.get_meetings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "meeting_id = meetings[-8]['id']\n",
    "trasncription = await vexa.get_transcription(meeting_session_id=meeting_id, use_index=False)\n",
    "if trasncription:   \n",
    "    df, formatted_input, start_datetime, speakers, transcript = trasncription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "meeting_df = joined_df[joined_df['meeting_id'].astype(str)==meeting_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = await MeetingSummary.extract(formatted_input, meeting_df,use_cache=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Dmitriy Grankin discussed the functionality of a new call assistant tool that records audio and allows users to chat during or after calls, enhancing communication and record-keeping (Call Assistant Tool Functionality)[1]. Sergio Goriachev shared insights from his experience as a solo founder of a startup in Portugal, focusing on the challenges and successes of raising angel investments (Startup Insights from Portugal)[2]. Dmitriy provided an update on his startup VEX, noting a gradual increase in users and the need for further development based on user feedback (VEX User Growth and Feedback)[4]. Sergio proposed integrating AI into travel planning and accommodation services to enhance user experience, suggesting a personalized assistant for finding accommodations (AI Integration in Travel Services)[5]. Both speakers emphasized the importance of understanding customer needs before product development (Understanding Customer Needs)[6]. Sergio explored the concept of tokenizing real estate to make investments more accessible (Tokenization of Real Estate)[7]. Dmitriy mentioned his focus on real-world assets (RWA) and the potential for liquidity in investments (RWA)[3]. They discussed the relevance of AI in their projects (AI)[0] and the importance of robotics for future developments (Robotics)[22]. Sergio described a crypto index being developed by his startup, which collects data based on market caps (Crypto Index)[12]. He also shared his background as a Data Quality Engineer and his experience with big data (Data Quality Engineer)[13][14]. Sergio mentioned CyberFant, a venture capital firm, and their investment in a startup creating personalized assistants (CyberFant)[15]. Dmitriy expressed interest in Alcor's cryonics services and their relevance to his long-term goals (Alcor)[23]. They discussed their experiences living in Argentina, Portugal, Turkey, and other countries, highlighting cultural differences and potential business opportunities (Argentina)[18], (Portugal)[19], (Turkey)[16], (Colombia)[20], (Brazil)[21], (France)[25], (Spain)[24]. Sergio mentioned the unique linguistic adaptations in Argentina, referring to Tokasteshan (Tokasteshan)[17]."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "Markdown(r.summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "meeting_df = meeting_df.set_index('summary_index').sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building vector index...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd00f642858949f7ad387adc9bcd71da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index built successfully!\n"
     ]
    }
   ],
   "source": [
    "from sampling import WeightedSampler\n",
    "\n",
    "sampler = WeightedSampler(\n",
    "        df=joined_df,\n",
    "        text_columns=['summary', 'topic_name', 'details','referenced_text','speaker_name'],\n",
    "        date_column='meeting_time',\n",
    "        decay_factor=0.\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = 'CyberFant'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sampled_df = sampler.sample(\n",
    "        query=q,\n",
    "        n_samples=200,\n",
    "        recency_weight=0.,\n",
    "        similarity_weight=1.\n",
    "    ).sort_values('meeting_timestamp')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "from core import generic_call_stream,system_msg,user_msg,assistant_msg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = sampled_df[['meeting_time','speaker_name','topic_name','summary','details']].to_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12484"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from core import count_tokens\n",
    "count_tokens(context)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The search results do not contain any information regarding \"CyberFant.\" Therefore, I cannot provide a report on this topic. If you have any other queries or need information on a different subject, please let me know.\n"
     ]
    }
   ],
   "source": [
    "r = await generic_call_stream([\n",
    "    system_msg(f'''{prompts.perplexity}. \n",
    "               You user is Dmitry Grankin, who is your user, who also participates the meetings in the context. \n",
    "               '''),\n",
    "    system_msg(f'''Today is {pd.to_datetime('today').strftime('%Y-%m-%d')}.'''),\n",
    "    system_msg('''Frequently misspelled names and terms: {misspelled}. Replace misspelled company names and terms if found in context.'''),\n",
    "    \n",
    "    user_msg(f'search results: {context}. First value of the row is index. Give comprehensive long report.'),\n",
    "    \n",
    "    user_msg(f'create comprehencive consice streight to the point report on the topic: {q}, based solely on the context.')\n",
    "],model='default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The search results do not contain any information regarding \"CyberFant.\" Therefore, I cannot provide a report on this topic. If you have any other queries or need information on a different subject, please let me know."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Markdown\n",
    "Markdown(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Olga Nemirovskaya discusses several aspects of SEO in the context of their marketing strategies. She emphasizes the importance of internal linking and domain authority as critical factors for SEO success. Olga explains that internal linking helps improve search rankings and that building domain authority through quality backlinks is essential for enhancing visibility.\n",
       "\n",
       "Additionally, she mentions the need for clear messaging on their website to improve client understanding and engagement, which ties into SEO practices. Olga also highlights the significance of using tools like Surfer SEO for optimizing content based on competitive analysis, indicating that they have been using it successfully for several years to improve their articles' performance in search engines[1][2][3][4]."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
