{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/app')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nest_asyncio import apply\n",
    "apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from chat import *\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from psql_helpers import (\n",
    "    async_session, get_session,\n",
    "\n",
    ")\n",
    "from vexa import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vexa token: 3ae04e20124d40babc5107e658c666b6\n",
      "User information retrieved successfully.\n"
     ]
    }
   ],
   "source": [
    "auth = VexaAuth()\n",
    "vexa = VexaAPI()\n",
    "user_id = (await vexa.get_user_info())['id']\n",
    "\n",
    "# Initialize search engines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to Elasticsearch at elasticsearch:9200\n"
     ]
    }
   ],
   "source": [
    "qdrant_engine = QdrantSearchEngine(os.getenv('VOYAGE_API_KEY'))\n",
    "es_engine = await ElasticsearchBM25.create() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_manager = UnifiedChatManager(\n",
    "        session=get_session(),\n",
    "        qdrant_engine=qdrant_engine,\n",
    "        es_engine=es_engine\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What is the weather in San Francisco?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "fronten_id = None\n",
    "thread_id = None\n",
    "content_id = None\n",
    "entity_id = None\n",
    "content_ids = None\n",
    "entity_ids = None\n",
    "model = \"gpt-4o-mini\"\n",
    "temperature = 0.0\n",
    "meta = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import jupyter_stream_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from psql_helpers import get_session\n",
    "\n",
    "@jupyter_stream_output(markdown=True)\n",
    "async def unified_chat(\n",
    "    query: str,\n",
    "    content_id: Optional[UUID] = None,\n",
    "    entity_id: Optional[int] = None,\n",
    "    content_ids: Optional[List[UUID]] = None,\n",
    "    entity_ids: Optional[List[int]] = None,\n",
    "    thread_id: Optional[str] = None,\n",
    "    temperature: float = 0.7\n",
    "):\n",
    "    \"\"\"\n",
    "    Unified chat function supporting both content and entity-based search\n",
    "    \n",
    "    Args:\n",
    "        query: The user's query\n",
    "        content_id: Optional single content ID for direct thread mapping\n",
    "        entity_id: Optional single entity ID for direct thread mapping\n",
    "        content_ids: Optional list of content IDs for search scope\n",
    "        entity_ids: Optional list of entity IDs for search scope\n",
    "        thread_id: Optional thread ID to continue conversation\n",
    "        temperature: Model temperature parameter\n",
    "    \"\"\"\n",
    "    \n",
    "    async with get_session() as session:\n",
    "        chat_manager = UnifiedChatManager(\n",
    "            session=session,\n",
    "            qdrant_engine=qdrant_engine,\n",
    "            es_engine=es_engine\n",
    "        )\n",
    "        \n",
    "        async for result in chat_manager.chat(\n",
    "            user_id=user_id,\n",
    "            query=query,\n",
    "            content_id=content_id,\n",
    "            entity_id=entity_id,\n",
    "            content_ids=content_ids,\n",
    "            entity_ids=entity_ids,\n",
    "            thread_id=thread_id,\n",
    "            temperature=temperature\n",
    "        ):\n",
    "            if 'chunk' in result:\n",
    "                yield result['chunk']\n",
    "            elif 'linked_output' in result:\n",
    "                yield result\n",
    "                \n",
    "            print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "In our recent discussions about software, particularly during the meetings, we focused on several key aspects:\n",
       "\n",
       "1. **API Integration**: In the meeting on January 23, 2025, you and Artem Puzik discussed the **authentication process** for integrating an API within an existing application. Artem emphasized that users would already be **authorized** when accessing the chat feature, which is crucial for ensuring a seamless user experience.\n",
       "\n",
       "2. **User Flow and Functionality**: During the meeting on January 21, 2025, you outlined the **user flow** for accessing meeting information. You mentioned that when a user clicks on a **meeting card**, they would see a right panel with **transcriptions** and a chat that operates in the context of that specific meeting. This highlights the importance of context in enhancing user interactions.\n",
       "\n",
       "3. **User Interface Design**: In another discussion on January 15, 2025, you and Alex Shevliakov explored the **functionality and design** of a chat application that integrates calls and speaker information. You raised concerns about the limitations of the current model's response system and discussed potential improvements for better user interaction, including **filtering options** for calls.\n",
       "\n",
       "These discussions reflect a strong focus on enhancing user experience through effective software design and integration. If you have specific areas of software development or features you'd like to delve deeper into, let me know!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'chunk': '!'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'thread_id': '3b93779b-78a3-4a2f-b0c3-01886cf2fda9',\n",
       " 'output': \"In our recent discussions about software, particularly during the meetings, we focused on several key aspects:\\n\\n1. **API Integration**: In the meeting on January 23, 2025, you and Artem Puzik discussed the **authentication process** for integrating an API within an existing application. Artem emphasized that users would already be **authorized** when accessing the chat feature, which is crucial for ensuring a seamless user experience.\\n\\n2. **User Flow and Functionality**: During the meeting on January 21, 2025, you outlined the **user flow** for accessing meeting information. You mentioned that when a user clicks on a **meeting card**, they would see a right panel with **transcriptions** and a chat that operates in the context of that specific meeting. This highlights the importance of context in enhancing user interactions.\\n\\n3. **User Interface Design**: In another discussion on January 15, 2025, you and Alex Shevliakov explored the **functionality and design** of a chat application that integrates calls and speaker information. You raised concerns about the limitations of the current model's response system and discussed potential improvements for better user interaction, including **filtering options** for calls.\\n\\nThese discussions reflect a strong focus on enhancing user experience through effective software design and integration. If you have specific areas of software development or features you'd like to delve deeper into, let me know!\",\n",
       " 'linked_output': \"In our recent discussions about software, particularly during the meetings, we focused on several key aspects:\\n\\n1. **API Integration**: In the meeting on January 23, 2025, you and Artem Puzik discussed the **authentication process** for integrating an API within an existing application. Artem emphasized that users would already be **authorized** when accessing the chat feature, which is crucial for ensuring a seamless user experience.\\n\\n2. **User Flow and Functionality**: During the meeting on January 21, 2025, you outlined the **user flow** for accessing meeting information. You mentioned that when a user clicks on a **meeting card**, they would see a right panel with **transcriptions** and a chat that operates in the context of that specific meeting. This highlights the importance of context in enhancing user interactions.\\n\\n3. **User Interface Design**: In another discussion on January 15, 2025, you and Alex Shevliakov explored the **functionality and design** of a chat application that integrates calls and speaker information. You raised concerns about the limitations of the current model's response system and discussed potential improvements for better user interaction, including **filtering options** for calls.\\n\\nThese discussions reflect a strong focus on enhancing user experience through effective software design and integration. If you have specific areas of software development or features you'd like to delve deeper into, let me know!\",\n",
       " 'service_content': {'output': \"In our recent discussions about software, particularly during the meetings, we focused on several key aspects:\\n\\n1. **API Integration**: In the meeting on January 23, 2025, you and Artem Puzik discussed the **authentication process** for integrating an API within an existing application. Artem emphasized that users would already be **authorized** when accessing the chat feature, which is crucial for ensuring a seamless user experience.\\n\\n2. **User Flow and Functionality**: During the meeting on January 21, 2025, you outlined the **user flow** for accessing meeting information. You mentioned that when a user clicks on a **meeting card**, they would see a right panel with **transcriptions** and a chat that operates in the context of that specific meeting. This highlights the importance of context in enhancing user interactions.\\n\\n3. **User Interface Design**: In another discussion on January 15, 2025, you and Alex Shevliakov explored the **functionality and design** of a chat application that integrates calls and speaker information. You raised concerns about the limitations of the current model's response system and discussed potential improvements for better user interaction, including **filtering options** for calls.\\n\\nThese discussions reflect a strong focus on enhancing user experience through effective software design and integration. If you have specific areas of software development or features you'd like to delve deeper into, let me know!\",\n",
       "  'context': \"## Meeting 1 - January 23, 2025 09:40\\n\\n- [2025-01-23 09:40:30] This chunk is part of a conversation between Artem Puzik and Dmitry Grankin discussing the integration of an API within an existing application. Artem is clarifying the authentication process and the handling of user tokens within the app, emphasizing that the user will already be authorized when accessing the chat feature.\\n  > Artem Puzik:  это же внутри уже готового приложения будет правильно ну то есть пользователь туда уже на эту страницу он придет авторизована или это просто что-то отдельная мне как бы окошко там авторизации я да если ты сейчас пойдешь там у тебя есть еще  можно взять пока ту страницу, которая есть, она там неадаптивная, надо будет адаптивнее справиться, но это потом.  там слово такое что сначала сначала у тебя идет google авторизация и сначала как пользователь  Нет, Дим, я о другом.  То есть, допустим, если моя страница, мой компонент или что-то там, API мое будет лежать уже внутри страницы, Твоего приложения, то есть авторизация, значит, уже пройдена.  Значит, этот токен у тебя где-то там лежит, я его найду, правильно?  Этот токен, ты его получаешь от приложения.  Женя, у тебя там как раз описано, как авторизация происходит, и ты его сохраняешь в руке.  Еще раз.  Да. Для того, чтобы дойти до этого чата, я уже у тебя в существующем Vexo App, да, уже какой-то путь прошел, правильно?  Авторизация.\\n\\n## Meeting 2 - January 21, 2025 15:36\\n\\n- [2025-01-21 15:36:56] The chunk is part of a discussion among Dmitriy Grankin, Artem Puzik, and Sergey Ryabenko about the user flow and functionality of an application that includes chat and meeting features. In this specific segment, Dmitriy outlines the first user flow related to accessing and interacting with meeting information, including the use of a meeting card and context for chat interactions.\\n  > Dmitriy Grankin:  чуть попозже сделаем вот в чем здесь ну как бы первый юзер флоу до начнем под давайте по user flow пойдем первый это Я хочу что-нибудь посмотреть по встрече, которая только прошла или какая-нибудь другая.  Я нажимаю на карт, на митинг-карт, у меня открывается...  Правая панель, в которой у меня есть транскрипция. И чат работает сейчас в контексте этой встречи. Контекст, да, это то, что мы подаем.  скажем так до чата да то есть контекст имеет разным образом определяется самый простой флоу от когда мы выбрали встречу, и он определяется по этой встрече, соответственно, по этой встрече.  Можем что-нибудь спросить про эту встречу, можем выбрать Quick Action.  Quick Action – это такой промпт, который исполняется автоматически при наступлении.\\n\\n## Meeting 4 - January 21, 2025 15:02\\n\\n- [2025-01-21 15:02:50] This chunk is part of a conversation between Mariana Montenegro and Dmitry Grankin, where Mariana discusses the AI Hub at Unicorn Factory Lisboa, describing it as one of several hubs focused on different themes, including gaming and sustainability. She also mentions its location near the Sporting stadium in Alvalade.\\n  > Mariana Montenegro:  right yeah so the ai hub is also is actually our fourth yeah hub so we also have gaming uh green hub which is focused on certain sustainability and also wet tree hub which is focused on wet tree well so yeah ai is focused on ai and it's our bigger biggest hub with the seven four for the space event a lot of offices yeah and where are you located right now their hub is in alvalade so near like sporting stadium you know Which one, Benfica?  No, the green one, Sporting, you know, Alfa-Latina.  Okay, okay.\\n\\n## Meeting 3 - January 15, 2025 14:07\\n\\n- [2025-01-15 14:07:51] The chunk is part of a discussion between Dmitriy Grankin and Alex Shevliakov about the functionality and design of a user interface for a chat application that integrates calls and speaker information. They are specifically addressing the limitations of a current model's response system and exploring how to improve user interaction with the interface, including the organization of calls and filtering options.\\n  > Dmitriy Grankin:  Курсор делает так, что моделька отвечает сырая, и в этом нет никакого смысла в контексте курсора, а в нашем контексте может быть даже и есть какой-то смысл, что ты как-то говоришь тебе от 5 не нужен у тебя тут есть внутри вот но вообще сейчас реализовано что это Просто рак без фильтра.  Рак без фильтра, окей.  Да, что это рак без фильтра, но вообще это хороший вопрос на обсуждение.  Стоит ли иметь...  голую модельку я бы может сделать что там будет голая моделька в сайт баре  вот мы сейчас пообсуждаем как будет выглядеть В сайт-баре, например, ты можешь выбрать какой-то из созвонов или выбрать все созвоны.  Когда ты выбираешь все созвоны, ты уже по всем созвонам.\\n\"}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await unified_chat(query=\"what did we say about software??\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
