{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/app')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# %%\n",
    "from qdrant_client import QdrantClient\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Connect to Qdrant\n",
    "\n",
    "# %%\n",
    "def get_qdrant_client():\n",
    "    \"\"\"Get Qdrant client with default settings\"\"\"\n",
    "    return QdrantClient(\n",
    "        host=\"qdrant\",  # Update if running in different environment\n",
    "        port=6333\n",
    "    )\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Query Recent Chunks\n",
    "\n",
    "# %%\n",
    "def get_recent_chunks(collection_name=\"meeting_chunks\", limit=100, hours_ago=24000*30):\n",
    "    \"\"\"\n",
    "    Retrieve the most recent chunks from Qdrant.\n",
    "    \n",
    "    Args:\n",
    "        collection_name (str): Name of the Qdrant collection\n",
    "        limit (int): Maximum number of chunks to retrieve\n",
    "        hours_ago (int): Look back period in hours\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame containing chunk data\n",
    "    \"\"\"\n",
    "    client = get_qdrant_client()\n",
    "    \n",
    "    # Calculate timestamp threshold\n",
    "    time_threshold = (datetime.utcnow() - timedelta(hours=hours_ago)).isoformat()\n",
    "    \n",
    "    # Search with filtering by timestamp\n",
    "    search_result = client.scroll(\n",
    "        collection_name=collection_name,\n",
    "        scroll_filter={\"must\": [\n",
    "            {\"key\": \"timestamp\", \"range\": {\"gte\": time_threshold}}\n",
    "        ]},\n",
    "        limit=limit,\n",
    "        with_payload=True,\n",
    "        with_vectors=True\n",
    "    )[0]  # scroll returns (points, next_page_offset)\n",
    "    \n",
    "    # Extract relevant fields from payload\n",
    "    chunks_data = []\n",
    "    for point in search_result:\n",
    "        payload = point.payload\n",
    "        chunks_data.append({\n",
    "            'id': point.id,\n",
    "            'timestamp': pd.to_datetime(payload.get('timestamp')),  # Convert to datetime\n",
    "            'meeting_id': payload.get('meeting_id'),\n",
    "            'content': payload.get('content'),\n",
    "            'contextualized_content': payload.get('contextualized_content'),\n",
    "            'chunk_index': payload.get('chunk_index'),\n",
    "            'topic': payload.get('topic'),\n",
    "            'speaker': payload.get('speaker'),\n",
    "            'speakers': payload.get('speakers'),\n",
    "            'vector_dim': len(point.vector) if point.vector else None\n",
    "        })\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(chunks_data)\n",
    "    \n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>meeting_id</th>\n",
       "      <th>content</th>\n",
       "      <th>contextualized_content</th>\n",
       "      <th>chunk_index</th>\n",
       "      <th>topic</th>\n",
       "      <th>speaker</th>\n",
       "      <th>speakers</th>\n",
       "      <th>vector_dim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>032b931a-ce25-4c41-9225-3896f4b6723c</td>\n",
       "      <td>2024-06-17 11:07:08.001148+00:00</td>\n",
       "      <td>649abab5-c1ad-4066-83c7-cb0161aea310</td>\n",
       "      <td>Polar Wanderer:  Да...</td>\n",
       "      <td>The chunk occurs in a conversation among various mystical characters discussing the functionality of a system, with Polar Wanderer responding affirmatively to a previous statement, indicating engagement in the ongoing dialogue.</td>\n",
       "      <td>7</td>\n",
       "      <td>Acknowledgment</td>\n",
       "      <td>Polar Wanderer</td>\n",
       "      <td>[Mystic Wizard, Polar Wanderer, Mystic Siren, Blazing Samurai, Mariner Comet]</td>\n",
       "      <td>1024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>04066c2a-403a-43bf-8723-0eb08d2ba4ea</td>\n",
       "      <td>2024-06-17 11:51:54.943091+00:00</td>\n",
       "      <td>125a5015-5712-495d-84f9-1f54737e7ac9</td>\n",
       "      <td>Polar Vulture:  И релизнем первую версию, и уже можно разгуляться и сделать вообще шину между сервисами.</td>\n",
       "      <td>The document is a conversation between Mystic Wizard and Polar Vulture discussing technical issues related to meeting transcriptions and session management in a software system. The chunk reflects Polar Vulture's optimism about releasing the first version of their project and the potential for future enhancements, such as creating a service bus between services.</td>\n",
       "      <td>8</td>\n",
       "      <td>Future Development Plans</td>\n",
       "      <td>Polar Vulture</td>\n",
       "      <td>[Polar Wanderer, Polar Vulture, Mystic Wizard, Harmonic Spirit]</td>\n",
       "      <td>1024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0424cb2e-44fd-4b56-baee-2efa70553ef5</td>\n",
       "      <td>2024-06-11 10:44:30.159113+00:00</td>\n",
       "      <td>48512bee-c060-4e74-8b05-ba19ea65ef9e</td>\n",
       "      <td>Nova Alchemist:  However, that said, rags have some limitations.  When we do rag search, we are using some kind of semantic similarity and vectorizing everything in the rag.  rack search we are using some kind of semantic similarity and vectorizing everything in the rack so here because we are vectorizing all the passages then we are losing all the connections and relationships that exist in the text because we are basically flattening the entire text and that exist in the text because we are basically flattening the entire text and represent it as a bunch of vectors.  So we are not really encoding all of the semantic intent in the text.  That's one of the problems with RAG in general or with any kind of vectorization.  That's one of the problems with rag in general, or with any kind of vectorization.  That's one of the problems with RAG in general, or with any kind of vectorization.  So to put it in more plain English, this process of vectorization of text chunks So to put it in more plain English, this process of vectorization of text chunks is really just embedding, turning, let's say the whole sentence, one sentence in the chunk.  is really just embedding, turning, let's say, the whole sentence, one sentence in the chunk.  like one word in the sentence versus another word, not to mention their interrelationship is not, it's embedded in the embeddings, but not necessarily like a very tight, very,  it doesn't pay, I don't know what's the right word to say.  Explicitly, right?  We are not explicitly describe the relationship between the words or the entities or the concept, right?  The sentences.  explicitly describe the relationship between the words or the entities or the concept, right? The sentences.  So that's basically, so we're losing right here.  We are not really including all of that information.</td>\n",
       "      <td>This chunk discusses the limitations of Retrieval Augmented Generation (RAG) systems, specifically focusing on the issues related to semantic similarity and vectorization, which result in the loss of connections and relationships within the text. It highlights how the process of embedding text into vectors fails to capture the explicit relationships between words, entities, and concepts, thereby compromising the semantic intent of the information.</td>\n",
       "      <td>5</td>\n",
       "      <td>Limitations of RAG Systems</td>\n",
       "      <td>Nova Alchemist</td>\n",
       "      <td>[Terra Tsunami, Nova Alchemist, Eternal Swan, Amber Swan, Polar Paladin, Vigilant Prophet]</td>\n",
       "      <td>1024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>05b47434-b5c9-4f24-82be-9cd3502e4d10</td>\n",
       "      <td>2024-06-17 11:51:54.943091+00:00</td>\n",
       "      <td>125a5015-5712-495d-84f9-1f54737e7ac9</td>\n",
       "      <td>Polar Vulture:  Хорошо, сейчас попробую. Насчет транскрипта вот здесь труднее. Почему? Если стриминг все еще не знает, если до стриминга все еще, точнее до engine все еще не дошло, что появилось новое.  сессия ассистент в натуре будет оперировать предыдущей сессии я прям правда не знаю как Вот транскрипт, да, окей, я сейчас трейловскую задачку заведу, попробую описать.  Вот, насчет этого подумаем.  Насчет ассистента, может, что-нибудь.  Да, вообще, блин, это все решится, когда мы...</td>\n",
       "      <td>The chunk is part of a conversation between Mystic Wizard and Polar Vulture discussing issues related to session management and transcription in a streaming context. Polar Vulture is addressing the challenges of ensuring that the assistant operates with the most current session data, highlighting potential delays in communication between the streaming service and the engine.</td>\n",
       "      <td>7</td>\n",
       "      <td>Transcription Challenges</td>\n",
       "      <td>Polar Vulture</td>\n",
       "      <td>[Polar Wanderer, Polar Vulture, Mystic Wizard, Harmonic Spirit]</td>\n",
       "      <td>1024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>087c9427-58ec-4079-b397-ed8a95cf8e3f</td>\n",
       "      <td>2024-06-17 11:51:54.943091+00:00</td>\n",
       "      <td>125a5015-5712-495d-84f9-1f54737e7ac9</td>\n",
       "      <td>Mystic Wizard:  Да, слушай, я предполагал, что как бы как там это работает, митинговые.  И если получает бэк, то он возвращает последнюю сессию, да?  Все так, абсолютно верно.  А он возвращает не последнюю сессию, а, видимо, все-таки предпоследнюю сессию.  Потому что, как ты видишь по скриншоту, и ассистент тоже получил контекст гораздо более ранний.  Your first time stamp, you see. 13 число. Сегодня у нас 17.  Я понял, кажется, о чем ты. Смотри, когда до...  Как быстро ты пошел запрашивать...  ассистента транскрипции.  Ну, транскрипцию, я как бы запустил.  Ну, то есть, через сколько секунд</td>\n",
       "      <td>The chunk is part of a conversation between Mystic Wizard and Polar Vulture discussing issues related to meeting sessions and transcription retrieval, specifically focusing on the timing and accuracy of session data being returned by the system.</td>\n",
       "      <td>1</td>\n",
       "      <td>Meeting Functionality</td>\n",
       "      <td>Mystic Wizard</td>\n",
       "      <td>[Polar Wanderer, Polar Vulture, Mystic Wizard, Harmonic Spirit]</td>\n",
       "      <td>1024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>e6b2b99f-523c-416b-b370-18a86324157d</td>\n",
       "      <td>2024-06-17 11:07:08.001148+00:00</td>\n",
       "      <td>649abab5-c1ad-4066-83c7-cb0161aea310</td>\n",
       "      <td>Blazing Samurai:  Ну что?</td>\n",
       "      <td>The chunk occurs in a conversation among various mystical characters discussing the functionality of a system, with Blazing Samurai expressing enthusiasm and prompting further discussion.</td>\n",
       "      <td>9</td>\n",
       "      <td>Inquiry</td>\n",
       "      <td>Blazing Samurai</td>\n",
       "      <td>[Mystic Wizard, Polar Wanderer, Mystic Siren, Blazing Samurai, Mariner Comet]</td>\n",
       "      <td>1024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>e6de3edc-2498-45a9-8324-b491602a902f</td>\n",
       "      <td>2024-06-17 14:44:39.887056+00:00</td>\n",
       "      <td>ee4e0b24-8c60-4788-9f88-b441b44cd0aa</td>\n",
       "      <td>Whispering Rogue:  Have a good evening. Bye.</td>\n",
       "      <td>The chunk is a closing remark from Whispering Rogue, following a discussion about a week that was different and the importance of communication within a team, indicating the end of a conversation.</td>\n",
       "      <td>3</td>\n",
       "      <td>Farewell wishes</td>\n",
       "      <td>Whispering Rogue</td>\n",
       "      <td>[Whispering Rogue]</td>\n",
       "      <td>1024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>e8512688-8657-47e5-93ed-6671fbd69164</td>\n",
       "      <td>2024-06-11 10:01:39.015022+00:00</td>\n",
       "      <td>947c4433-b43d-47db-8ac7-f18d29f91c01</td>\n",
       "      <td>Polar Paladin:  So instead of searching through every single chunk, when we are So instead of searching through every single chunk, when we are chunking the documents, Essentially, in this solution, what we can do is to include the document summary.  So document summary is the same because each we summarize the document and we add that as part of the embedding part of the metadata with the embedding and then we save them into the vector database so when user ask a document to the user question and then we can go oh now that the answer is in this particular document now i can only go and fetch related chunks from that document and then generate the response so that's the very first solution for this problem however although this one  Что происходит?  Summary as a metadata to each embedding.</td>\n",
       "      <td>The discussion revolves around enhancing the efficiency of the Retrieval-Augmented Generation (RAG) system by addressing the challenges of chunking documents for better search retrieval. The focus is on incorporating document summaries as metadata in the embedding process, allowing for more targeted searches that can quickly identify relevant chunks when a user poses a question. This approach aims to streamline the retrieval process and improve the accuracy of responses generated by the system.</td>\n",
       "      <td>7</td>\n",
       "      <td>Including document summaries in chunking</td>\n",
       "      <td>Polar Paladin</td>\n",
       "      <td>[Sunny Storm, Arcane Sphinx, Mystic Wizard, Enchanted Tempest, Nova Alchemist, Polar Wanderer, Lunar Sorcerer, Tempest Vulture, Polar Paladin, Wandering Sniper, Titanic Ninja, Thundering Vulture]</td>\n",
       "      <td>1024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>f817cfd4-9485-4795-acaa-e60d2bd10f3e</td>\n",
       "      <td>2024-06-17 14:44:39.887056+00:00</td>\n",
       "      <td>ee4e0b24-8c60-4788-9f88-b441b44cd0aa</td>\n",
       "      <td>Whispering Rogue:  week that was different sorry it was me this is what happened when i don't speak too much yeah that's what's happening everybody breaks that is that's not scrum okay okay guys Thanks, and keep in touch.</td>\n",
       "      <td>The chunk is part of a conversation where \"Whispering Rogue\" reflects on a week that was unusual, apologizing for not communicating enough, and acknowledging the impact on team dynamics, while encouraging continued communication among team members.</td>\n",
       "      <td>2</td>\n",
       "      <td>Scrum methodology</td>\n",
       "      <td>Whispering Rogue</td>\n",
       "      <td>[Whispering Rogue]</td>\n",
       "      <td>1024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>fd785536-08a0-42ae-ae63-1b5f32e34b35</td>\n",
       "      <td>2024-06-11 10:01:39.015022+00:00</td>\n",
       "      <td>947c4433-b43d-47db-8ac7-f18d29f91c01</td>\n",
       "      <td>Nova Alchemist:  If you think about it, it's like a hierarchical order.  So when you ask a question, first you go and search through these sub-document summaries a question first you go and search through these sub-document summaries to just pinpoint part of the document that is related to the user query and then when you find that part you can search further the relevant chunks that are related to that particular When you find that part, you can search further the relevant chunks that are When you find that part, you can search further the relevant chunks that are related to that related to that particular summary.  particular summary.  It obviously works better than not really having any document summary, because in this scenario, you have to search through tens of thousands of chunks every time user is asking a question.  Right. So the latency is much more here. The accuracy obviously will lower this one.  more here, the accuracy obviously will lower.  This one is better and this one is even better.  I see. Yeah, this makes total sense, especially potentially suitable for longer documents.</td>\n",
       "      <td>The discussion revolves around enhancing the retrieval process in a Retrieval-Augmented Generation (RAG) system by implementing a hierarchical approach to document chunking. Nova Alchemist explains how searching through sub-document summaries can improve the accuracy and efficiency of finding relevant information, particularly in lengthy documents, by first identifying the most pertinent sections before delving into specific chunks.</td>\n",
       "      <td>12</td>\n",
       "      <td>Hierarchical order in document summaries</td>\n",
       "      <td>Nova Alchemist</td>\n",
       "      <td>[Sunny Storm, Arcane Sphinx, Mystic Wizard, Enchanted Tempest, Nova Alchemist, Polar Wanderer, Lunar Sorcerer, Tempest Vulture, Polar Paladin, Wandering Sniper, Titanic Ninja, Thundering Vulture]</td>\n",
       "      <td>1024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>67 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      id                        timestamp  \\\n",
       "0   032b931a-ce25-4c41-9225-3896f4b6723c 2024-06-17 11:07:08.001148+00:00   \n",
       "1   04066c2a-403a-43bf-8723-0eb08d2ba4ea 2024-06-17 11:51:54.943091+00:00   \n",
       "2   0424cb2e-44fd-4b56-baee-2efa70553ef5 2024-06-11 10:44:30.159113+00:00   \n",
       "3   05b47434-b5c9-4f24-82be-9cd3502e4d10 2024-06-17 11:51:54.943091+00:00   \n",
       "4   087c9427-58ec-4079-b397-ed8a95cf8e3f 2024-06-17 11:51:54.943091+00:00   \n",
       "..                                   ...                              ...   \n",
       "62  e6b2b99f-523c-416b-b370-18a86324157d 2024-06-17 11:07:08.001148+00:00   \n",
       "63  e6de3edc-2498-45a9-8324-b491602a902f 2024-06-17 14:44:39.887056+00:00   \n",
       "64  e8512688-8657-47e5-93ed-6671fbd69164 2024-06-11 10:01:39.015022+00:00   \n",
       "65  f817cfd4-9485-4795-acaa-e60d2bd10f3e 2024-06-17 14:44:39.887056+00:00   \n",
       "66  fd785536-08a0-42ae-ae63-1b5f32e34b35 2024-06-11 10:01:39.015022+00:00   \n",
       "\n",
       "                              meeting_id  \\\n",
       "0   649abab5-c1ad-4066-83c7-cb0161aea310   \n",
       "1   125a5015-5712-495d-84f9-1f54737e7ac9   \n",
       "2   48512bee-c060-4e74-8b05-ba19ea65ef9e   \n",
       "3   125a5015-5712-495d-84f9-1f54737e7ac9   \n",
       "4   125a5015-5712-495d-84f9-1f54737e7ac9   \n",
       "..                                   ...   \n",
       "62  649abab5-c1ad-4066-83c7-cb0161aea310   \n",
       "63  ee4e0b24-8c60-4788-9f88-b441b44cd0aa   \n",
       "64  947c4433-b43d-47db-8ac7-f18d29f91c01   \n",
       "65  ee4e0b24-8c60-4788-9f88-b441b44cd0aa   \n",
       "66  947c4433-b43d-47db-8ac7-f18d29f91c01   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           content  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Polar Wanderer:  Да...   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         Polar Vulture:  И релизнем первую версию, и уже можно разгуляться и сделать вообще шину между сервисами.   \n",
       "2   Nova Alchemist:  However, that said, rags have some limitations.  When we do rag search, we are using some kind of semantic similarity and vectorizing everything in the rag.  rack search we are using some kind of semantic similarity and vectorizing everything in the rack so here because we are vectorizing all the passages then we are losing all the connections and relationships that exist in the text because we are basically flattening the entire text and that exist in the text because we are basically flattening the entire text and represent it as a bunch of vectors.  So we are not really encoding all of the semantic intent in the text.  That's one of the problems with RAG in general or with any kind of vectorization.  That's one of the problems with rag in general, or with any kind of vectorization.  That's one of the problems with RAG in general, or with any kind of vectorization.  So to put it in more plain English, this process of vectorization of text chunks So to put it in more plain English, this process of vectorization of text chunks is really just embedding, turning, let's say the whole sentence, one sentence in the chunk.  is really just embedding, turning, let's say, the whole sentence, one sentence in the chunk.  like one word in the sentence versus another word, not to mention their interrelationship is not, it's embedded in the embeddings, but not necessarily like a very tight, very,  it doesn't pay, I don't know what's the right word to say.  Explicitly, right?  We are not explicitly describe the relationship between the words or the entities or the concept, right?  The sentences.  explicitly describe the relationship between the words or the entities or the concept, right? The sentences.  So that's basically, so we're losing right here.  We are not really including all of that information.   \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          Polar Vulture:  Хорошо, сейчас попробую. Насчет транскрипта вот здесь труднее. Почему? Если стриминг все еще не знает, если до стриминга все еще, точнее до engine все еще не дошло, что появилось новое.  сессия ассистент в натуре будет оперировать предыдущей сессии я прям правда не знаю как Вот транскрипт, да, окей, я сейчас трейловскую задачку заведу, попробую описать.  Вот, насчет этого подумаем.  Насчет ассистента, может, что-нибудь.  Да, вообще, блин, это все решится, когда мы...   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            Mystic Wizard:  Да, слушай, я предполагал, что как бы как там это работает, митинговые.  И если получает бэк, то он возвращает последнюю сессию, да?  Все так, абсолютно верно.  А он возвращает не последнюю сессию, а, видимо, все-таки предпоследнюю сессию.  Потому что, как ты видишь по скриншоту, и ассистент тоже получил контекст гораздо более ранний.  Your first time stamp, you see. 13 число. Сегодня у нас 17.  Я понял, кажется, о чем ты. Смотри, когда до...  Как быстро ты пошел запрашивать...  ассистента транскрипции.  Ну, транскрипцию, я как бы запустил.  Ну, то есть, через сколько секунд   \n",
       "..                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             ...   \n",
       "62                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       Blazing Samurai:  Ну что?   \n",
       "63                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    Whispering Rogue:  Have a good evening. Bye.   \n",
       "64                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                Polar Paladin:  So instead of searching through every single chunk, when we are So instead of searching through every single chunk, when we are chunking the documents, Essentially, in this solution, what we can do is to include the document summary.  So document summary is the same because each we summarize the document and we add that as part of the embedding part of the metadata with the embedding and then we save them into the vector database so when user ask a document to the user question and then we can go oh now that the answer is in this particular document now i can only go and fetch related chunks from that document and then generate the response so that's the very first solution for this problem however although this one  Что происходит?  Summary as a metadata to each embedding.   \n",
       "65                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   Whispering Rogue:  week that was different sorry it was me this is what happened when i don't speak too much yeah that's what's happening everybody breaks that is that's not scrum okay okay guys Thanks, and keep in touch.   \n",
       "66                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Nova Alchemist:  If you think about it, it's like a hierarchical order.  So when you ask a question, first you go and search through these sub-document summaries a question first you go and search through these sub-document summaries to just pinpoint part of the document that is related to the user query and then when you find that part you can search further the relevant chunks that are related to that particular When you find that part, you can search further the relevant chunks that are When you find that part, you can search further the relevant chunks that are related to that related to that particular summary.  particular summary.  It obviously works better than not really having any document summary, because in this scenario, you have to search through tens of thousands of chunks every time user is asking a question.  Right. So the latency is much more here. The accuracy obviously will lower this one.  more here, the accuracy obviously will lower.  This one is better and this one is even better.  I see. Yeah, this makes total sense, especially potentially suitable for longer documents.   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 contextualized_content  \\\n",
       "0                                                                                                                                                                                                                                                                                   The chunk occurs in a conversation among various mystical characters discussing the functionality of a system, with Polar Wanderer responding affirmatively to a previous statement, indicating engagement in the ongoing dialogue.   \n",
       "1                                                                                                                                          The document is a conversation between Mystic Wizard and Polar Vulture discussing technical issues related to meeting transcriptions and session management in a software system. The chunk reflects Polar Vulture's optimism about releasing the first version of their project and the potential for future enhancements, such as creating a service bus between services.   \n",
       "2                                                   This chunk discusses the limitations of Retrieval Augmented Generation (RAG) systems, specifically focusing on the issues related to semantic similarity and vectorization, which result in the loss of connections and relationships within the text. It highlights how the process of embedding text into vectors fails to capture the explicit relationships between words, entities, and concepts, thereby compromising the semantic intent of the information.   \n",
       "3                                                                                                                             The chunk is part of a conversation between Mystic Wizard and Polar Vulture discussing issues related to session management and transcription in a streaming context. Polar Vulture is addressing the challenges of ensuring that the assistant operates with the most current session data, highlighting potential delays in communication between the streaming service and the engine.   \n",
       "4                                                                                                                                                                                                                                                                 The chunk is part of a conversation between Mystic Wizard and Polar Vulture discussing issues related to meeting sessions and transcription retrieval, specifically focusing on the timing and accuracy of session data being returned by the system.   \n",
       "..                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  ...   \n",
       "62                                                                                                                                                                                                                                                                                                                          The chunk occurs in a conversation among various mystical characters discussing the functionality of a system, with Blazing Samurai expressing enthusiasm and prompting further discussion.   \n",
       "63                                                                                                                                                                                                                                                                                                                 The chunk is a closing remark from Whispering Rogue, following a discussion about a week that was different and the importance of communication within a team, indicating the end of a conversation.   \n",
       "64  The discussion revolves around enhancing the efficiency of the Retrieval-Augmented Generation (RAG) system by addressing the challenges of chunking documents for better search retrieval. The focus is on incorporating document summaries as metadata in the embedding process, allowing for more targeted searches that can quickly identify relevant chunks when a user poses a question. This approach aims to streamline the retrieval process and improve the accuracy of responses generated by the system.   \n",
       "65                                                                                                                                                                                                                                                             The chunk is part of a conversation where \"Whispering Rogue\" reflects on a week that was unusual, apologizing for not communicating enough, and acknowledging the impact on team dynamics, while encouraging continued communication among team members.   \n",
       "66                                                                 The discussion revolves around enhancing the retrieval process in a Retrieval-Augmented Generation (RAG) system by implementing a hierarchical approach to document chunking. Nova Alchemist explains how searching through sub-document summaries can improve the accuracy and efficiency of finding relevant information, particularly in lengthy documents, by first identifying the most pertinent sections before delving into specific chunks.   \n",
       "\n",
       "    chunk_index                                     topic           speaker  \\\n",
       "0             7                            Acknowledgment    Polar Wanderer   \n",
       "1             8                  Future Development Plans     Polar Vulture   \n",
       "2             5                Limitations of RAG Systems    Nova Alchemist   \n",
       "3             7                  Transcription Challenges     Polar Vulture   \n",
       "4             1                     Meeting Functionality     Mystic Wizard   \n",
       "..          ...                                       ...               ...   \n",
       "62            9                                   Inquiry   Blazing Samurai   \n",
       "63            3                           Farewell wishes  Whispering Rogue   \n",
       "64            7  Including document summaries in chunking     Polar Paladin   \n",
       "65            2                         Scrum methodology  Whispering Rogue   \n",
       "66           12  Hierarchical order in document summaries    Nova Alchemist   \n",
       "\n",
       "                                                                                                                                                                                               speakers  \\\n",
       "0                                                                                                                         [Mystic Wizard, Polar Wanderer, Mystic Siren, Blazing Samurai, Mariner Comet]   \n",
       "1                                                                                                                                       [Polar Wanderer, Polar Vulture, Mystic Wizard, Harmonic Spirit]   \n",
       "2                                                                                                            [Terra Tsunami, Nova Alchemist, Eternal Swan, Amber Swan, Polar Paladin, Vigilant Prophet]   \n",
       "3                                                                                                                                       [Polar Wanderer, Polar Vulture, Mystic Wizard, Harmonic Spirit]   \n",
       "4                                                                                                                                       [Polar Wanderer, Polar Vulture, Mystic Wizard, Harmonic Spirit]   \n",
       "..                                                                                                                                                                                                  ...   \n",
       "62                                                                                                                        [Mystic Wizard, Polar Wanderer, Mystic Siren, Blazing Samurai, Mariner Comet]   \n",
       "63                                                                                                                                                                                   [Whispering Rogue]   \n",
       "64  [Sunny Storm, Arcane Sphinx, Mystic Wizard, Enchanted Tempest, Nova Alchemist, Polar Wanderer, Lunar Sorcerer, Tempest Vulture, Polar Paladin, Wandering Sniper, Titanic Ninja, Thundering Vulture]   \n",
       "65                                                                                                                                                                                   [Whispering Rogue]   \n",
       "66  [Sunny Storm, Arcane Sphinx, Mystic Wizard, Enchanted Tempest, Nova Alchemist, Polar Wanderer, Lunar Sorcerer, Tempest Vulture, Polar Paladin, Wandering Sniper, Titanic Ninja, Thundering Vulture]   \n",
       "\n",
       "    vector_dim  \n",
       "0         1024  \n",
       "1         1024  \n",
       "2         1024  \n",
       "3         1024  \n",
       "4         1024  \n",
       "..         ...  \n",
       "62        1024  \n",
       "63        1024  \n",
       "64        1024  \n",
       "65        1024  \n",
       "66        1024  \n",
       "\n",
       "[67 rows x 10 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_recent_chunks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
